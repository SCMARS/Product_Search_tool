
import requests
import json
import logging
import http.client
import ssl
from typing import List, Dict, Any
from urllib.parse import quote_plus, urlencode
from bs4 import BeautifulSoup
import os


logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


ALIEXPRESS_BASE = "https://www.aliexpress.com/wholesale"
USER_AGENT = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) " \
             "AppleWebKit/537.36 (KHTML, like Gecko) " \
             "Chrome/115.0 Safari/537.36"
HEADERS = {"User-Agent": USER_AGENT}


def search_aliexpress(query: str, limit: int = 20) -> List[Dict[str, Any]]:
    """
    ĞŸĞ¾Ğ¸ÑĞº Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ¾Ğ² Ğ½Ğ° AliExpress Ğ¢ĞĞ›Ğ¬ĞšĞ Ñ‡ĞµÑ€ĞµĞ· API
    """
    results = []
    
    try:
        # Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ API Ğ¿Ğ¾Ğ¸ÑĞº
        api_results = search_aliexpress_api(query, limit)
        if api_results:
            logger.info(f"âœ… RapidAPI Ğ¿Ğ¾Ğ¸ÑĞº ÑƒÑĞ¿ĞµÑˆĞµĞ½: Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾ {len(api_results)} Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ¾Ğ²")
            return api_results
        else:
            logger.warning("âš ï¸ API Ğ½Ğµ Ğ²ĞµÑ€Ğ½ÑƒĞ» Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹")
            return results
    except Exception as e:
        logger.error(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° AliExpress API: {e}")
        return results


# Ğ£Ğ´Ğ°Ğ»ÑĞµĞ¼ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ scrape_aliexpress - Ğ±Ğ¾Ğ»ÑŒÑˆĞµ Ğ½Ğµ Ğ½ÑƒĞ¶Ğ½Ğ°
# def scrape_aliexpress(query: str, limit: int = 20) -> List[Dict[str, Any]]:
#     """Ğ¡ĞºÑ€Ğ°Ğ¿Ğ¸Ğ½Ğ³ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² Ğ¿Ğ¾Ğ¸ÑĞºĞ° AliExpress Ñ Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ½Ñ‹Ğ¼Ğ¸ ÑĞµĞ»ĞµĞºÑ‚Ğ¾Ñ€Ğ°Ğ¼Ğ¸"""
#     results: List[Dict[str, Any]] = []
#     encoded = quote_plus(query)
#     url = f"{ALIEXPRESS_BASE}?SearchText={encoded}"
#     logger.info(f"ğŸ” Ğ¡ĞºÑ€ĞµĞ¹Ğ¿ĞµÑ€: Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ {url}")

#     try:
#         headers = {
#             'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
#             'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
#             'Accept-Language': 'en-US,en;q=0.9',
#             'Accept-Encoding': 'gzip, deflate, br',
#             'Connection': 'keep-alive',
#             'Upgrade-Insecure-Requests': '1',
#             'Cache-Control': 'no-cache'
#         }

#         resp = requests.get(url, headers=headers, timeout=20)
#         if resp.status_code != 200:
#             logger.error(f"âŒ Ğ¡ĞºÑ€Ğ°Ğ¿Ğ¸Ğ½Ğ³ Ğ½Ğµ ÑƒĞ´Ğ°Ğ»ÑÑ, ÑÑ‚Ğ°Ñ‚ÑƒÑ: {resp.status_code}")
#             return results

#         soup = BeautifulSoup(resp.text, 'html.parser')

#         # ĞĞ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ½Ñ‹Ğµ ÑĞµĞ»ĞµĞºÑ‚Ğ¾Ñ€Ñ‹ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ¸ÑĞºĞ° Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ¾Ğ²
#         card_selectors = [
#             'div[data-widget-cid]',  # Ğ½Ğ¾Ğ²Ñ‹Ğ¹ ÑĞµĞ»ĞµĞºÑ‚Ğ¾Ñ€
#             'div._3t7zg',  # ÑÑ‚Ğ°Ñ€Ñ‹Ğ¹ ÑĞµĞ»ĞµĞºÑ‚Ğ¾Ñ€
#             'div.list-item',
#             'div.product-item',
#             'div[class*="item"]',
#             'a[href*="/item/"]',  # ÑÑÑ‹Ğ»ĞºĞ¸ Ğ½Ğ° Ñ‚Ğ¾Ğ²Ğ°Ñ€Ñ‹
#             'div[class*="product"]',
#             'div[class*="card"]',
#             'div[class*="list"]'
#         ]

#         items = []
#         for selector in card_selectors:
#             items = soup.select(selector)
#             if items:
#                 logger.info(f"âœ… ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ {len(items)} Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ¾Ğ² Ñ ÑĞµĞ»ĞµĞºÑ‚Ğ¾Ñ€Ğ¾Ğ¼: {selector}")
#                 break

#         if not items:
#             logger.warning("âš ï¸ Ğ¢Ğ¾Ğ²Ğ°Ñ€Ñ‹ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ñ‹ Ğ½Ğ¸ Ñ Ğ¾Ğ´Ğ½Ğ¸Ğ¼ ÑĞµĞ»ĞµĞºÑ‚Ğ¾Ñ€Ğ¾Ğ¼")
#             # ĞŸĞ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞµĞ¼ Ğ½Ğ°Ğ¹Ñ‚Ğ¸ Ğ»ÑĞ±Ñ‹Ğµ ÑÑÑ‹Ğ»ĞºĞ¸ Ğ½Ğ° Ñ‚Ğ¾Ğ²Ğ°Ñ€Ñ‹
#             items = soup.find_all('a', href=lambda x: x and '/item/' in x)
#             if items:
#                 logger.info(f"âœ… ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ {len(items)} ÑÑÑ‹Ğ»Ğ¾Ğº Ğ½Ğ° Ñ‚Ğ¾Ğ²Ğ°Ñ€Ñ‹")

#         for card in items[:limit]:
#             try:
#                 # Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµĞ¼ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ°
#                 name = ""
#                 url = ""
#                 price = ""
#                 image = ""

#                 # ĞĞ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ°
#                 title_selectors = [
#                     'a[href*="/item/"] span',
#                     'a[href*="/item/"]',
#                     'h3 a',
#                     'a[title]',
#                     '.item-title a',
#                     'a span',
#                     'span[class*="title"]',
#                     'div[class*="title"]'
#                 ]

#                 for title_sel in title_selectors:
#                     title_el = card.select_one(title_sel)
#                     if title_el:
#                         name = title_el.get_text(strip=True) or title_el.get('title', '')
#                         if name and len(name) > 5:
#                             break

#                 # Ğ•ÑĞ»Ğ¸ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾, Ğ¿Ğ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞµĞ¼ Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡ÑŒ Ğ¸Ğ· Ğ°Ñ‚Ñ€Ğ¸Ğ±ÑƒÑ‚Ğ° title
#                 if not name:
#                     title_attr = card.get('title') or card.find('a', title=True)
#                     if title_attr:
#                         name = title_attr.get('title', '') if hasattr(title_attr, 'get') else str(title_attr)

#                 if not name:
#                     continue

#                 # Ğ¡ÑÑ‹Ğ»ĞºĞ° Ğ½Ğ° Ñ‚Ğ¾Ğ²Ğ°Ñ€
#                 link_selectors = [
#                     'a[href*="/item/"]',
#                     'a[href*="/product/"]',
#                     'a[title]'
#                 ]

#                 for link_sel in link_selectors:
#                     link_el = card.select_one(link_sel)
#                     if link_el:
#                         url = link_el.get('href', '')
#                         if url and ('/item/' in url or '/product/' in url):
#                             if not url.startswith('http'):
#                                 url = f"https://www.aliexpress.com{url}"
#                             break

#                 # Ğ¦ĞµĞ½Ğ°
#                 price_selectors = [
#                     'span[class*="price"]',
#                     'div[class*="price"]',
#                     '.price',
#                     'span[data-currency]',
#                     'div[data-currency]'
#                 ]

#                 for price_sel in price_selectors:
#                     price_el = card.select_one(price_sel)
#                     if price_el:
#                         price_text = price_el.get_text(strip=True)
#                         if price_text and any(char.isdigit() for char in price_text):
#                             price = price_text
#                             break

#                 # Ğ˜Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ
#                 img_selectors = [
#                     'img[src*="ae01.alicdn.com"]',
#                     'img[data-src]',
#                     'img[src]',
#                     'img'
#                 ]

#                 for img_sel in img_selectors:
#                     img_el = card.select_one(img_sel)
#                     if img_el:
#                         image = img_el.get('src') or img_el.get('data-src') or img_el.get('data-lazy-src')
#                         if image and ('ae01.alicdn.com' in image or 'alicdn.com' in image):
#                             break

#                 # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚
#                 if name and url:
#                     result = {
#                         'name': name,
#                         'price': price or "Ğ¦ĞµĞ½Ğ° Ğ½Ğµ ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ°",
#                         'image': image,
#                         'url': url,
#                         'relevance_score': 100,  # Ğ‘Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğ¹ score
#                         'source': 'AliExpress'
#                     }
#                     results.append(result)
#                     logger.info(f"âœ… Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ĞµĞ½ Ñ‚Ğ¾Ğ²Ğ°Ñ€ AliExpress: {name[:50]}...")

#             except Exception as e:
#                 logger.error(f"Error processing AliExpress item: {e}")
#                 continue

#         logger.info(f"ğŸ¯ ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ {len(results)} Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ¾Ğ² Ğ½Ğ° AliExpress")
#         return results

#     except Exception as e:
#         logger.error(f"Error scraping AliExpress: {e}")
#         return results


def search_aliexpress_api(query: str, limit: int = 20) -> List[Dict[str, Any]]:
    """Ğ Ğ°Ğ±Ğ¾Ñ‚Ğ° Ñ‡ĞµÑ€ĞµĞ· RapidAPI AliExpress DataHub"""
    # Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ğ¿Ñ€ĞµĞ´Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ĞµĞ½Ğ½Ñ‹Ğ¹ ĞºĞ»ÑÑ‡
    api_key = "30fbd6eb3cmsh237fee1bd93a580p167775jsne5d2245df248"
    
    logger.info(f"ğŸ”‘ Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ RapidAPI ĞºĞ»ÑÑ‡: {api_key[:10]}...")

    try:
        headers = {
            'x-rapidapi-key': api_key,
            'x-rapidapi-host': "aliexpress-datahub.p.rapidapi.com"
        }

        # Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ requests Ğ²Ğ¼ĞµÑÑ‚Ğ¾ http.client Ğ´Ğ»Ñ Ğ±Ğ¾Ğ»ĞµĞµ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾Ğ¹ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹
        url = "https://aliexpress-datahub.p.rapidapi.com/item_search_2"
        params = {
            "q": query,
            "page": "1"
        }

        logger.info(f"ğŸ” API Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ: {url} Ñ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ°Ğ¼Ğ¸ {params}")

        response = requests.get(url, headers=headers, params=params, timeout=30)
        
        logger.info(f"ğŸ“¡ API Ğ¾Ñ‚Ğ²ĞµÑ‚: {response.status_code}")

        if response.status_code != 200:
            logger.error(f"âŒ API Ğ²ĞµÑ€Ğ½ÑƒĞ» Ğ¾ÑˆĞ¸Ğ±ĞºÑƒ {response.status_code}: {response.text}")
            return []

        data_json = response.json()
        items = []

        logger.info(f"ğŸ“¦ ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ñ‹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ: {type(data_json)}")

        if 'result' in data_json:
            result = data_json['result']

            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ÑÑ‚Ğ°Ñ‚ÑƒÑ
            status = result.get('status', {})
            if status.get('code') != 200:
                logger.warning(f"âš ï¸ API ÑÑ‚Ğ°Ñ‚ÑƒÑ: {status.get('code')}, ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ: {status.get('msg', {})}")

            result_list = result.get('resultList', [])
            logger.info(f"ğŸ“‹ ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ¾Ğ² Ğ² Ğ¾Ñ‚Ğ²ĞµÑ‚Ğµ: {len(result_list)}")

            for prod_wrapper in result_list[:limit]:
                try:
                    # Ğ¢Ğ¾Ğ²Ğ°Ñ€ Ğ½Ğ°Ñ…Ğ¾Ğ´Ğ¸Ñ‚ÑÑ Ğ² Ğ¿Ğ¾Ğ»Ğµ 'item'
                    prod = prod_wrapper.get('item', {})
                    if not prod:
                        continue

                    # Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµĞ¼ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ
                    name = prod.get('title', '')

                    # Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµĞ¼ Ñ†ĞµĞ½Ñƒ Ğ¸Ğ· sku.def
                    price = ""
                    sku = prod.get('sku', {})
                    if sku and 'def' in sku:
                        sku_def = sku['def']
                        price = sku_def.get('promotionPrice') or sku_def.get('price')

                    # Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµĞ¼ URL
                    item_url = prod.get('itemUrl', '')
                    full_url = f"https:{item_url}" if item_url.startswith('//') else item_url
                    if not full_url.startswith('http'):
                        full_url = f"https://www.aliexpress.com{item_url}"

                    # Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµĞ¼ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ
                    image = prod.get('image', '')
                    if image and image.startswith('//'):
                        image = f"https:{image}"

                    if name and len(name) > 5:
                        items.append({
                            'name': name,
                            'price': f"${price}" if price else "Ğ¦ĞµĞ½Ğ° Ğ½Ğµ ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ°",
                            'url': full_url,
                            'image': image,
                            'relevance_score': 85,
                            'source': 'AliExpress'
                        })
                        logger.info(f"âœ… API Ñ‚Ğ¾Ğ²Ğ°Ñ€: {name[:50]} - ${price}")

                except Exception as e:
                    logger.error(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ°: {e}")
                    continue

        if items:
            logger.info(f"âœ… AliExpress API ÑƒÑĞ¿ĞµÑˆĞµĞ½: Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾ {len(items)} Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ¾Ğ²")
            return items
        else:
            logger.warning("âš ï¸ AliExpress API Ğ½Ğµ Ğ²ĞµÑ€Ğ½ÑƒĞ» Ñ‚Ğ¾Ğ²Ğ°Ñ€Ñ‹")
            return []

    except Exception as e:
        logger.error(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° AliExpress API: {e}")
        return []



if __name__ == '__main__':
    results = search_aliexpress('iphone 15 pro max', 5)
    for idx, item in enumerate(results, 1):
        print(f"{idx}. {item['name']} - {item['price']} -> {item['url']}")
