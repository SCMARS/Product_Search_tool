
import requests
import json
import logging
import http.client
import ssl
from typing import List, Dict, Any
from urllib.parse import quote_plus, urlencode
from bs4 import BeautifulSoup
import os


logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


ALIEXPRESS_BASE = "https://www.aliexpress.com/wholesale"
USER_AGENT = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) " \
             "AppleWebKit/537.36 (KHTML, like Gecko) " \
             "Chrome/115.0 Safari/537.36"
HEADERS = {"User-Agent": USER_AGENT}


def search_aliexpress(query: str, limit: int = 20) -> List[Dict[str, Any]]:
    """
    –ü–æ–∏—Å–∫ —Ç–æ–≤–∞—Ä–æ–≤ –Ω–∞ AliExpress –¢–û–õ–¨–ö–û —á–µ—Ä–µ–∑ API
    """
    results = []
    
    try:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ API –ø–æ–∏—Å–∫
        api_results = search_aliexpress_api(query, limit)
        if api_results:
            logger.info(f"‚úÖ RapidAPI –ø–æ–∏—Å–∫ —É—Å–ø–µ—à–µ–Ω: –Ω–∞–π–¥–µ–Ω–æ {len(api_results)} —Ç–æ–≤–∞—Ä–æ–≤")
            return api_results
        else:
            logger.warning("‚ö†Ô∏è API –Ω–µ –≤–µ—Ä–Ω—É–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã")
            return results
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ AliExpress API: {e}")
        return results


# –£–¥–∞–ª—è–µ–º —Ñ—É–Ω–∫—Ü–∏—é scrape_aliexpress - –±–æ–ª—å—à–µ –Ω–µ –Ω—É–∂–Ω–∞
# def scrape_aliexpress(query: str, limit: int = 20) -> List[Dict[str, Any]]:
#     """–°–∫—Ä–∞–ø–∏–Ω–≥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞ AliExpress —Å –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–º–∏ —Å–µ–ª–µ–∫—Ç–æ—Ä–∞–º–∏"""
#     results: List[Dict[str, Any]] = []
#     encoded = quote_plus(query)
#     url = f"{ALIEXPRESS_BASE}?SearchText={encoded}"
#     logger.info(f"üîç –°–∫—Ä–µ–π–ø–µ—Ä: –∑–∞–ø—Ä–æ—Å {url}")

#     try:
#         headers = {
#             'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
#             'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
#             'Accept-Language': 'en-US,en;q=0.9',
#             'Accept-Encoding': 'gzip, deflate, br',
#             'Connection': 'keep-alive',
#             'Upgrade-Insecure-Requests': '1',
#             'Cache-Control': 'no-cache'
#         }

#         resp = requests.get(url, headers=headers, timeout=20)
#         if resp.status_code != 200:
#             logger.error(f"‚ùå –°–∫—Ä–∞–ø–∏–Ω–≥ –Ω–µ —É–¥–∞–ª—Å—è, —Å—Ç–∞—Ç—É—Å: {resp.status_code}")
#             return results

#         soup = BeautifulSoup(resp.text, 'html.parser')

#         # –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ç–æ–≤–∞—Ä–æ–≤
#         card_selectors = [
#             'div[data-widget-cid]',  # –Ω–æ–≤—ã–π —Å–µ–ª–µ–∫—Ç–æ—Ä
#             'div._3t7zg',  # —Å—Ç–∞—Ä—ã–π —Å–µ–ª–µ–∫—Ç–æ—Ä
#             'div.list-item',
#             'div.product-item',
#             'div[class*="item"]',
#             'a[href*="/item/"]',  # —Å—Å—ã–ª–∫–∏ –Ω–∞ —Ç–æ–≤–∞—Ä—ã
#             'div[class*="product"]',
#             'div[class*="card"]',
#             'div[class*="list"]'
#         ]

#         items = []
#         for selector in card_selectors:
#             items = soup.select(selector)
#             if items:
#                 logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(items)} —Ç–æ–≤–∞—Ä–æ–≤ —Å —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–º: {selector}")
#                 break

#         if not items:
#             logger.warning("‚ö†Ô∏è –¢–æ–≤–∞—Ä—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –Ω–∏ —Å –æ–¥–Ω–∏–º —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–º")
#             # –ü–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –ª—é–±—ã–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ —Ç–æ–≤–∞—Ä—ã
#             items = soup.find_all('a', href=lambda x: x and '/item/' in x)
#             if items:
#                 logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(items)} —Å—Å—ã–ª–æ–∫ –Ω–∞ —Ç–æ–≤–∞—Ä—ã")

#         for card in items[:limit]:
#             try:
#                 # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Ç–æ–≤–∞—Ä–∞
#                 name = ""
#                 url = ""
#                 price = ""
#                 image = ""

#                 # –ù–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞
#                 title_selectors = [
#                     'a[href*="/item/"] span',
#                     'a[href*="/item/"]',
#                     'h3 a',
#                     'a[title]',
#                     '.item-title a',
#                     'a span',
#                     'span[class*="title"]',
#                     'div[class*="title"]'
#                 ]

#                 for title_sel in title_selectors:
#                     title_el = card.select_one(title_sel)
#                     if title_el:
#                         name = title_el.get_text(strip=True) or title_el.get('title', '')
#                         if name and len(name) > 5:
#                             break

#                 # –ï—Å–ª–∏ –Ω–∞–∑–≤–∞–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –ø–æ–ø—Ä–æ–±—É–µ–º –∏–∑–≤–ª–µ—á—å –∏–∑ –∞—Ç—Ä–∏–±—É—Ç–∞ title
#                 if not name:
#                     title_attr = card.get('title') or card.find('a', title=True)
#                     if title_attr:
#                         name = title_attr.get('title', '') if hasattr(title_attr, 'get') else str(title_attr)

#                 if not name:
#                     continue

#                 # –°—Å—ã–ª–∫–∞ –Ω–∞ —Ç–æ–≤–∞—Ä
#                 link_selectors = [
#                     'a[href*="/item/"]',
#                     'a[href*="/product/"]',
#                     'a[title]'
#                 ]

#                 for link_sel in link_selectors:
#                     link_el = card.select_one(link_sel)
#                     if link_el:
#                         url = link_el.get('href', '')
#                         if url and ('/item/' in url or '/product/' in url):
#                             if not url.startswith('http'):
#                                 url = f"https://www.aliexpress.com{url}"
#                             break

#                 # –¶–µ–Ω–∞
#                 price_selectors = [
#                     'span[class*="price"]',
#                     'div[class*="price"]',
#                     '.price',
#                     'span[data-currency]',
#                     'div[data-currency]'
#                 ]

#                 for price_sel in price_selectors:
#                     price_el = card.select_one(price_sel)
#                     if price_el:
#                         price_text = price_el.get_text(strip=True)
#                         if price_text and any(char.isdigit() for char in price_text):
#                             price = price_text
#                             break

#                 # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
#                 img_selectors = [
#                     'img[src*="ae01.alicdn.com"]',
#                     'img[data-src]',
#                     'img[src]',
#                     'img'
#                 ]

#                 for img_sel in img_selectors:
#                     img_el = card.select_one(img_sel)
#                     if img_el:
#                         image = img_el.get('src') or img_el.get('data-src') or img_el.get('data-lazy-src')
#                         if image and ('ae01.alicdn.com' in image or 'alicdn.com' in image):
#                             break

#                 # –°–æ–∑–¥–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
#                 if name and url:
#                     result = {
#                         'name': name,
#                         'price': price or "–¶–µ–Ω–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞",
#                         'image': image,
#                         'url': url,
#                         'relevance_score': 100,  # –ë–∞–∑–æ–≤—ã–π score
#                         'source': 'AliExpress'
#                     }
#                     results.append(result)
#                     logger.info(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω —Ç–æ–≤–∞—Ä AliExpress: {name[:50]}...")

#             except Exception as e:
#                 logger.error(f"Error processing AliExpress item: {e}")
#                 continue

#         logger.info(f"üéØ –ù–∞–π–¥–µ–Ω–æ {len(results)} —Ç–æ–≤–∞—Ä–æ–≤ –Ω–∞ AliExpress")
#         return results

#     except Exception as e:
#         logger.error(f"Error scraping AliExpress: {e}")
#         return results


def search_aliexpress_api(query: str, limit: int = 20) -> List[Dict[str, Any]]:
    """–†–∞–±–æ—Ç–∞ —á–µ—Ä–µ–∑ RapidAPI AliExpress DataHub"""
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –∫–ª—é—á
    api_key = "30fbd6eb3cmsh237fee1bd93a580p167775jsne5d2245df248"
    
    logger.info(f"üîë –ò—Å–ø–æ–ª—å–∑—É–µ–º RapidAPI –∫–ª—é—á: {api_key[:10]}...")

    try:
        headers = {
            'x-rapidapi-key': api_key,
            'x-rapidapi-host': "aliexpress-datahub.p.rapidapi.com"
        }

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º requests –≤–º–µ—Å—Ç–æ http.client –¥–ª—è –±–æ–ª–µ–µ –ø—Ä–æ—Å—Ç–æ–π —Ä–∞–±–æ—Ç—ã
        url = "https://aliexpress-datahub.p.rapidapi.com/item_search_2"
        params = {
            "q": query,
            "page": "1"
        }

        logger.info(f"üîç API –∑–∞–ø—Ä–æ—Å: {url} —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ {params}")

        response = requests.get(url, headers=headers, params=params, timeout=30)
        
        logger.info(f"üì° API –æ—Ç–≤–µ—Ç: {response.status_code}")

        if response.status_code != 200:
            logger.error(f"‚ùå API –≤–µ—Ä–Ω—É–ª –æ—à–∏–±–∫—É {response.status_code}: {response.text}")
            return []

        data_json = response.json()
        items = []

        logger.info(f"üì¶ –ü–æ–ª—É—á–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ: {type(data_json)}")

        if 'result' in data_json:
            result = data_json['result']

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å
            status = result.get('status', {})
            if status.get('code') != 200:
                logger.warning(f"‚ö†Ô∏è API —Å—Ç–∞—Ç—É—Å: {status.get('code')}, —Å–æ–æ–±—â–µ–Ω–∏–µ: {status.get('msg', {})}")

            result_list = result.get('resultList', [])
            logger.info(f"üìã –ù–∞–π–¥–µ–Ω–æ —Ç–æ–≤–∞—Ä–æ–≤ –≤ –æ—Ç–≤–µ—Ç–µ: {len(result_list)}")

            for prod_wrapper in result_list[:limit]:
                try:
                    # –¢–æ–≤–∞—Ä –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –ø–æ–ª–µ 'item'
                    prod = prod_wrapper.get('item', {})
                    if not prod:
                        continue

                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ
                    name = prod.get('title', '')

                    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ü–µ–Ω—É –∏–∑ sku.def
                    price = ""
                    sku = prod.get('sku', {})
                    if sku and 'def' in sku:
                        sku_def = sku['def']
                        price = sku_def.get('promotionPrice') or sku_def.get('price')

                    # –ò–∑–≤–ª–µ–∫–∞–µ–º URL
                    item_url = prod.get('itemUrl', '')
                    full_url = f"https:{item_url}" if item_url.startswith('//') else item_url
                    if not full_url.startswith('http'):
                        full_url = f"https://www.aliexpress.com{item_url}"

                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                    image = prod.get('image', '')
                    if image and image.startswith('//'):
                        image = f"https:{image}"

                    if name and len(name) > 5:
                        items.append({
                            'name': name,
                            'price': f"${price}" if price else "–¶–µ–Ω–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞",
                            'url': full_url,
                            'image': image,
                            'relevance_score': 85,
                            'source': 'AliExpress'
                        })
                        logger.info(f"‚úÖ API —Ç–æ–≤–∞—Ä: {name[:50]} - ${price}")

                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–æ–≤–∞—Ä–∞: {e}")
                    continue

        if items:
            logger.info(f"‚úÖ AliExpress API —É—Å–ø–µ—à–µ–Ω: –Ω–∞–π–¥–µ–Ω–æ {len(items)} —Ç–æ–≤–∞—Ä–æ–≤")
            return items
        else:
            logger.warning("‚ö†Ô∏è AliExpress API –Ω–µ –≤–µ—Ä–Ω—É–ª —Ç–æ–≤–∞—Ä—ã")
            return []

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ AliExpress API: {e}")
        return []



if __name__ == '__main__':
    results = search_aliexpress('iphone 15 pro max', 5)
    for idx, item in enumerate(results, 1):
        print(f"{idx}. {item['name']} - {item['price']} -> {item['url']}")
