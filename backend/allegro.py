import asyncio
import logging
import os
import requests
import re
from bs4 import BeautifulSoup
from typing import List, Dict, Any
from playwright.async_api import async_playwright, Page
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)



class AllegroScraper:
    def __init__(self):
        self.search_url = "https://allegro.pl"
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'pl-PL,pl;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        }

    def calculate_relevance_score(self, title: str, query: str) -> float:
        """
        –§—É–Ω–∫—Ü–∏—è —Ä–∞—Å—á–µ—Ç–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ —Ç–æ–≤–∞—Ä–∞
        """
        if not title or not query:
            return 0

        # –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –∫–∏—Ä–∏–ª–ª–∏—Ü—ã –∏ —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏–∏ –¥–ª—è –í–°–ï–• —Ç–æ–≤–∞—Ä–æ–≤
        transliteration_map = {
            # –ú–∞—Å—Å–∞–∂–µ—Ä—ã
            '–º–∞—Å—Å–∞–∂–æ—Ä': ['masa≈ºer', 'massage', 'massager', 'masa≈º'],
            '–º–∞—Å—Å–∞–∂–µ—Ä': ['masa≈ºer', 'massage', 'massager', 'masa≈º'],
            # –¢–µ—Ö–Ω–∏–∫–∞ Apple
            '–º–∞–∫–±—É–∫': ['macbook'],
            '–∞–π—Ñ–æ–Ω': ['iphone'],
            '–∞–π–ø–∞–¥': ['ipad'],
            '–ø—Ä–æ': ['pro'],
            '—ç–ø–ª': ['apple'],
            '–≤–æ—á': ['watch'],
            '—ç–ø–ª –≤–æ—á': ['apple watch'],

            # –î—Ä—É–≥–∏–µ –±—Ä–µ–Ω–¥—ã —Ç–µ–ª–µ—Ñ–æ–Ω–æ–≤
            '—Å–∞–º—Å—É–Ω–≥': ['samsung'],
            '—Å—è–æ–º–∏': ['xiaomi'],
            '–∫—Å—è–æ–º–∏': ['xiaomi'],
            '—Ö—É–∞–≤–µ–π': ['huawei'],
            '—Ö–æ–Ω–æ—Ä': ['honor'],
            '–æ–ø–æ': ['oppo'],
            '–≤–∏–≤–æ': ['vivo'],
            '—Ä–µ–∞–ª–º–∏': ['realme'],
            '–≤–∞–Ω –ø–ª–∞—Å': ['oneplus'],
            '–≥—É–≥–ª': ['google'],
            '–ø–∏–∫—Å–µ–ª—å': ['pixel'],
            '–Ω–æ–∫–∏–∞': ['nokia'],
            '–º–æ—Ç–æ—Ä–æ–ª–∞': ['motorola'],

            # –ë—Ä–µ–Ω–¥—ã –Ω–æ—É—Ç–±—É–∫–æ–≤
            '–¥–µ–ª': ['dell'],
            '—Ö–ø': ['hp'],
            '–ª–µ–Ω–æ–≤–æ': ['lenovo'],
            '–∞—Å—É—Å': ['asus'],
            '—ç–π—Å–µ—Ä': ['acer'],
            '–º—Å–∏': ['msi'],
            '—Å–æ–Ω–∏': ['sony'],
            # –î—Ä—É–≥–∏–µ –ø–æ–ø—É–ª—è—Ä–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã
            '—Ç–µ–ª–µ—Ñ–æ–Ω': ['phone', 'telefon', 'smartphone'],
            '–Ω–∞—É—à–Ω–∏–∫–∏': ['headphones', 's≈Çuchawki', 'earphones'],
            '—á–∞—Å—ã': ['watch', 'zegarek', 'smartwatch'],
            '—Ñ–æ—Ç–æ–∞–ø–ø–∞—Ä–∞—Ç': ['camera', 'aparat', 'kamera'],
            '–Ω–æ—É—Ç–±—É–∫': ['laptop', 'notebook'],
            '–ø–ª–∞–Ω—à–µ—Ç': ['tablet'],
            '–∫–ª–∞–≤–∏–∞—Ç—É—Ä–∞': ['keyboard', 'klawiatura'],
            '–º—ã—à—å': ['mouse', 'mysz'],
            # –ê–∫—Å–µ—Å—Å—É–∞—Ä—ã
            '—á–µ—Ö–æ–ª': ['case', 'etui', 'cover', 'obudowa'],
            '–∑–∞—Ä—è–¥–∫–∞': ['charger', '≈Çadowarka'],
            '–∫–∞–±–µ–ª—å': ['cable', 'kabel'],
            '–ø–æ–¥—Å—Ç–∞–≤–∫–∞': ['stand', 'podstawka'],
            '—Å—É–º–∫–∞': ['bag', 'torba'],
            '–∑–∞—â–∏—Ç–∞': ['protector', 'protection'],
            
            # –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã
            'silicone caulking tools': ['silicone seam tool', 'caulking tool', 'silicone tool', 'seam tool'],
            'caulking tools': ['caulking tool', 'seam tool', 'silicone tool'],
            'silicone tools': ['silicone tool', 'caulking tool', 'seam tool'],
            'electric mosquito swatter': ['elektrische fliegenklatsche', 'electric fly swatter', 'mosquito killer'],
            'mosquito swatter': ['fliegenklatsche', 'fly swatter', 'mosquito killer'],
            'electric fly swatter': ['elektrische fliegenklatsche', 'electric mosquito swatter', 'fly killer']
        }

        query_lower = query.lower()
        title_lower = title.lower()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—é - –ù–ï –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å—Ä–∞–∑—É, –∞ –¥–æ–±–∞–≤–ª—è–µ–º –∫ –æ–±—â–µ–º—É score
        transliteration_bonus = 0
        for ru_word, en_variants in transliteration_map.items():
            if ru_word in query_lower:
                for en_variant in en_variants:
                    if en_variant in title_lower:
                        transliteration_bonus += 50  # –ë–æ–Ω—É—Å –∑–∞ —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—é
                        break

        # –ë–∞–∑–æ–≤—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        score = 0
        
        # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –≤—Å–µ–π —Ñ—Ä–∞–∑—ã
        if query_lower in title_lower:
            score += 150
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Å–ª–æ–≤–∞
        query_words = query_lower.split()
        title_words = title_lower.split()
        
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å–æ–≤–ø–∞–¥–∞—é—â–∏–µ —Å–ª–æ–≤–∞
        matched_words = 0
        for q_word in query_words:
            if len(q_word) > 2:  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–ª–æ–≤–∞
                for t_word in title_words:
                    if q_word in t_word or t_word in q_word:
                        matched_words += 1
                        break
        
        # –ë–æ–Ω—É—Å –∑–∞ —Å–æ–≤–ø–∞–¥–∞—é—â–∏–µ —Å–ª–æ–≤–∞
        if len(query_words) > 0:
            match_percentage = matched_words / len(query_words)
            score += int(match_percentage * 60)
        
        # –ë–æ–Ω—É—Å –∑–∞ –ø–æ—Ä—è–¥–æ–∫ —Å–ª–æ–≤
        last_pos = -1
        ordered_count = 0
        for q_word in query_words:
            if len(q_word) > 2:
                pos = title_lower.find(q_word)
                if pos > last_pos:
                    ordered_count += 1
                    last_pos = pos
        
        if len(query_words) > 1:
            order_bonus = (ordered_count / len(query_words)) * 40
            score += int(order_bonus)
        
        # –ë–æ–Ω—É—Å –∑–∞ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        key_words = ['tool', 'kit', 'set', 'professional', 'premium', 'electric', 'electronic']
        for key_word in key_words:
            if key_word in title_lower:
                score += 10
        
        # –®—Ç—Ä–∞—Ñ –∑–∞ –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Å–ª–æ–≤–∞
        irrelevant_words = ['case', 'cover', 'protector', 'screen', 'film', 'adapter', 'cable', 'charger']
        for word in irrelevant_words:
            if word in title_lower and word not in query_lower:
                score -= 20
        
        # –®—Ç—Ä–∞—Ñ –∑–∞ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è
        if len(title) > 200:
            score -= 25
        
        # –®—Ç—Ä–∞—Ñ –∑–∞ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è
        if len(title) < 10:
            score -= 30
        
        # –î–æ–±–∞–≤–ª—è–µ–º –±–æ–Ω—É—Å –∑–∞ —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—é
        score += transliteration_bonus
        
        return score

    def translate_query(self, query: str) -> str:
        """–ü—Ä–æ—Å—Ç–æ–π –ø–µ—Ä–µ–≤–æ–¥ —Ä—É—Å—Å–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –Ω–∞ –ø–æ–ª—å—Å–∫–∏–π/–∞–Ω–≥–ª–∏–π—Å–∫–∏–π"""
        translations = {
            '—Ç–µ–ª–µ—Ñ–æ–Ω': 'telefon', '—Å–º–∞—Ä—Ç—Ñ–æ–Ω': 'smartfon', '–∞–π—Ñ–æ–Ω': 'iphone',
            '—Å–∞–º—Å—É–Ω–≥': 'samsung', '–Ω–æ—É—Ç–±—É–∫': 'laptop', '–∫–æ–º–ø—å—é—Ç–µ—Ä': 'komputer',
            '–ø–ª–∞–Ω—à–µ—Ç': 'tablet', '–Ω–∞—É—à–Ω–∏–∫–∏': 's≈Çuchawki', '–∫–æ–ª–æ–Ω–∫–∏': 'g≈Ço≈õniki',
            '–∫–æ—Ñ–µ–º–∞—à–∏–Ω–∞': 'ekspres do kawy', '–ø—ã–ª–µ—Å–æ—Å': 'odkurzacz',
            '—Ö–æ–ª–æ–¥–∏–ª—å–Ω–∏–∫': 'lod√≥wka', '—Å—Ç–∏—Ä–∞–ª—å–Ω–∞—è –º–∞—à–∏–Ω–∞': 'pralka',
            '–∫—Ä–æ—Å—Å–æ–≤–∫–∏': 'buty sportowe', '–∫—É—Ä—Ç–∫–∞': 'kurtka', '–¥–∂–∏–Ω—Å—ã': 'jeansy',
            '–º–µ–±–µ–ª—å': 'meble', '—Å—Ç–æ–ª': 'st√≥≈Ç', '—Å—Ç—É–ª': 'krzes≈Ço', '–¥–∏–≤–∞–Ω': 'sofa'
        }

        query_lower = query.lower()
        for ru_word, pl_word in translations.items():
            if ru_word in query_lower:
                query_lower = query_lower.replace(ru_word, pl_word)

        return query_lower

    def get_proxy_config(self):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –ø—Ä–æ–∫—Å–∏ —Å —Ä–æ—Ç–∞—Ü–∏–µ–π"""
        import os
        import random

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è –ø—Ä–æ–∫—Å–∏
        proxy_server = os.getenv('PROXY_SERVER')
        proxy_username = os.getenv('PROXY_USERNAME')
        proxy_password = os.getenv('PROXY_PASSWORD')

        if proxy_server:
            proxy_config = {
                'server': proxy_server
            }

            if proxy_username and proxy_password:
                proxy_config['username'] = proxy_username
                proxy_config['password'] = proxy_password

            logger.info(f"üåê –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –ø—Ä–æ–∫—Å–∏: {proxy_server}")
            return proxy_config

        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–ø–∏—Å–æ–∫ –ø—Ä–æ–∫—Å–∏ –∏–∑ —Ñ–∞–π–ª–∞
        try:
            proxy_file_path = os.path.join(os.path.dirname(__file__), 'proxy_list.txt')
            with open(proxy_file_path, 'r') as f:
                proxy_list = [line.strip() for line in f.readlines() if line.strip()]

            if proxy_list:
                # –í—ã–±–∏—Ä–∞–µ–º —Å–ª—É—á–∞–π–Ω—ã–π –ø—Ä–æ–∫—Å–∏
                selected_proxy_ip = random.choice(proxy_list)
                selected_proxy = f"http://{selected_proxy_ip}"

                logger.info(f"üåê –í—ã–±—Ä–∞–Ω —Å–ª—É—á–∞–π–Ω—ã–π –ø—Ä–æ–∫—Å–∏: {selected_proxy}")
                return {'server': selected_proxy}

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å–ø–∏—Å–æ–∫ –ø—Ä–æ–∫—Å–∏: {e}")

        logger.info("üåê –ü—Ä–æ–∫—Å–∏ –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä—è–º–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ")
        return None

    def change_ip_address(self):
        """–ü–æ–ø—ã—Ç–∫–∞ —Å–º–µ–Ω—ã IP –∞–¥—Ä–µ—Å–∞"""
        try:
            import subprocess
            import os

            # –ú–µ—Ç–æ–¥ 1: –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫ —Å–µ—Ç–µ–≤–æ–≥–æ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ (—Ç—Ä–µ–±—É–µ—Ç sudo)
            vpn_command = os.getenv('VPN_RECONNECT_COMMAND')
            if vpn_command:
                logger.info("üîÑ –ü—ã—Ç–∞–µ–º—Å—è —Å–º–µ–Ω–∏—Ç—å IP —á–µ—Ä–µ–∑ VPN...")
                subprocess.run(vpn_command.split(), timeout=30)
                import time
                time.sleep(10)  # –ñ–¥–µ–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
                return True

            # –ú–µ—Ç–æ–¥ 2: –ö–æ–º–∞–Ω–¥–∞ –¥–ª—è —Å–º–µ–Ω—ã IP (–∑–∞–≤–∏—Å–∏—Ç –æ—Ç –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞)
            ip_change_command = os.getenv('IP_CHANGE_COMMAND')
            if ip_change_command:
                logger.info("üîÑ –ü—ã—Ç–∞–µ–º—Å—è —Å–º–µ–Ω–∏—Ç—å IP...")
                subprocess.run(ip_change_command.split(), timeout=30)
                import time
                time.sleep(5)
                return True

        except Exception as e:
            logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–º–µ–Ω–∏—Ç—å IP: {e}")

        return False

    def get_current_ip(self):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ IP –∞–¥—Ä–µ—Å–∞"""
        try:
            import requests
            response = requests.get('https://httpbin.org/ip', timeout=10)
            if response.status_code == 200:
                ip_data = response.json()
                return ip_data.get('origin', 'Unknown')
        except Exception as e:
            logger.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å IP: {e}")

        return "Unknown"

    def test_proxy(self, proxy_config):
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –ø—Ä–æ–∫—Å–∏"""
        if not proxy_config:
            return True

        try:
            import requests
            proxies = {
                'http': proxy_config['server'],
                'https': proxy_config['server']
            }

            # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø—Ä–æ–∫—Å–∏ –Ω–∞ –ø—Ä–æ—Å—Ç–æ–º —Å–∞–π—Ç–µ
            response = requests.get('http://httpbin.org/ip',
                                  proxies=proxies,
                                  timeout=10)

            if response.status_code == 200:
                ip_data = response.json()
                logger.info(f"‚úÖ –ü—Ä–æ–∫—Å–∏ —Ä–∞–±–æ—Ç–∞–µ—Ç, IP: {ip_data.get('origin', 'Unknown')}")
                return True
            else:
                logger.warning(f"‚ö†Ô∏è –ü—Ä–æ–∫—Å–∏ –≤–µ—Ä–Ω—É–ª —Å—Ç–∞—Ç—É—Å: {response.status_code}")
                return False

        except Exception as e:
            logger.warning(f"‚ùå –ü—Ä–æ–∫—Å–∏ –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç: {e}")
            return False

    def get_working_proxy(self, max_attempts=5):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–∞–±–æ—á–µ–≥–æ –ø—Ä–æ–∫—Å–∏ —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏"""
        for attempt in range(max_attempts):
            proxy_config = self.get_proxy_config()

            if not proxy_config:
                return None

            if self.test_proxy(proxy_config):
                return proxy_config

            logger.info(f"üîÑ –ü–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_attempts}: –ø—Ä–æ–±—É–µ–º –¥—Ä—É–≥–æ–π –ø—Ä–æ–∫—Å–∏...")

        logger.warning("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Ä–∞–±–æ—á–∏–π –ø—Ä–æ–∫—Å–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä—è–º–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ")
        return None

    async def detect_captcha(self, page):
        """–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∫–∞–ø—á–∏ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ"""
        try:
            # –ò—â–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã –∫–∞–ø—á–∏
            captcha_selectors = [
                'iframe[src*="captcha"]',
                'div[class*="captcha"]',
                'img[src*="captcha"]',
                '[data-testid*="captcha"]',
                'form[action*="captcha"]',
                '.g-recaptcha',
                '#captcha',
                'text="Przepisz kod z obrazka"',
                'text="Aplikacja przekroczy≈Ça limit"'
            ]

            for selector in captcha_selectors:
                element = page.locator(selector).first
                if await element.count() > 0:
                    logger.warning(f"ü§ñ –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –∫–∞–ø—á–∞: {selector}")
                    return True

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ–∫—Å—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
            page_content = await page.content()
            captcha_keywords = [
                'captcha',
                'Przepisz kod z obrazka',
                'Aplikacja przekroczy≈Ça limit zapyta≈Ñ',
                'przekroczy≈Ça limit',
                'Kod b≈Çƒôdu',
                'POTWIERD≈π',
                'ffb8115a-3756-4f23-a833-80d38e2',  # –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –∫–æ–¥ –æ—à–∏–±–∫–∏
                'Captcha',
                'limit zapyta≈Ñ'
            ]

            for keyword in captcha_keywords:
                if keyword.lower() in page_content.lower():
                    logger.warning(f"ü§ñ –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –∫–∞–ø—á–∞ –ø–æ –∫–ª—é—á–µ–≤–æ–º—É —Å–ª–æ–≤—É: {keyword}")
                    return True

            return False

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∫–∞–ø—á–∏: {e}")
            return False

    async def solve_captcha_2captcha(self, page):
        """–†–µ—à–µ–Ω–∏–µ –∫–∞–ø—á–∏ —á–µ—Ä–µ–∑ 2captcha —Å–µ—Ä–≤–∏—Å"""
        try:
            import os
            api_key = os.getenv('CAPTCHA_API_KEY')

            if not api_key:
                logger.error("‚ùå API –∫–ª—é—á 2captcha –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")
                logger.info("üí° –î–æ–±–∞–≤—å—Ç–µ CAPTCHA_API_KEY –≤ —Ñ–∞–π–ª .env")
                return False

            logger.info(f"üîë –ò—Å–ø–æ–ª—å–∑—É–µ–º 2captcha API –∫–ª—é—á: {api_key[:10]}...")

            # –î–µ–ª–∞–µ–º —Å–∫—Ä–∏–Ω—à–æ—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å –∫–∞–ø—á–µ–π
            screenshot_path = 'captcha_screenshot.png'
            await page.screenshot(path=screenshot_path, full_page=True)

            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ 2captcha
            from twocaptcha import TwoCaptcha
            solver = TwoCaptcha(api_key)

            logger.info("ü§ñ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∫–∞–ø—á—É –≤ 2captcha...")

            try:
                result = solver.normal(screenshot_path)
                captcha_text = result['code']
                logger.info(f"‚úÖ –ö–∞–ø—á–∞ —Ä–µ—à–µ–Ω–∞: {captcha_text}")

                # –ò—â–µ–º –ø–æ–ª–µ –≤–≤–æ–¥–∞ –∫–∞–ø—á–∏ –∏ –≤–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                input_selectors = [
                    'input[name*="captcha"]',
                    'input[id*="captcha"]',
                    'input[type="text"]',
                    'input[placeholder*="kod"]'
                ]

                for selector in input_selectors:
                    input_element = page.locator(selector).first
                    if await input_element.count() > 0:
                        await input_element.fill(captcha_text)
                        logger.info(f"‚úÖ –í–≤–µ–¥–µ–Ω –∫–æ–¥ –∫–∞–ø—á–∏ –≤ –ø–æ–ª–µ: {selector}")
                        break

                # –ò—â–µ–º –∫–Ω–æ–ø–∫—É –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è
                submit_selectors = [
                    'button:has-text("POTWIERD≈π")',
                    'button[type="submit"]',
                    'input[type="submit"]',
                    'button:has-text("Confirm")',
                    'button:has-text("Submit")'
                ]

                for selector in submit_selectors:
                    submit_button = page.locator(selector).first
                    if await submit_button.count() > 0:
                        await submit_button.click()
                        logger.info(f"‚úÖ –ù–∞–∂–∞—Ç–∞ –∫–Ω–æ–ø–∫–∞ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è: {selector}")
                        break

                # –ñ–¥–µ–º –∑–∞–≥—Ä—É–∑–∫–∏ –ø–æ—Å–ª–µ —Ä–µ—à–µ–Ω–∏—è –∫–∞–ø—á–∏
                await page.wait_for_load_state("networkidle", timeout=10000)

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∏—Å—á–µ–∑–ª–∞ –ª–∏ –∫–∞–ø—á–∞
                if not await self.detect_captcha(page):
                    logger.info("‚úÖ –ö–∞–ø—á–∞ —É—Å–ø–µ—à–Ω–æ —Ä–µ—à–µ–Ω–∞!")
                    return True
                else:
                    logger.warning("‚ö†Ô∏è –ö–∞–ø—á–∞ –≤—Å–µ –µ—â–µ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç")
                    return False

            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ä–µ—à–µ–Ω–∏—è –∫–∞–ø—á–∏ —á–µ—Ä–µ–∑ 2captcha: {e}")
                return False

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ solve_captcha_2captcha: {e}")
            return False

    def search_products_simple(self, query: str) -> List[Dict[str, Any]]:
        """
        –£–ª—É—á—à–µ–Ω–Ω—ã–π –ø—Ä–æ—Å—Ç–æ–π –ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ HTTP –∑–∞–ø—Ä–æ—Å—ã
        """
        products = []

        try:
            import time
            import random
            import urllib.parse

            # –ü–µ—Ä–µ–≤–æ–¥–∏–º –∑–∞–ø—Ä–æ—Å
            translated_query = self.translate_query(query)
            encoded_query = urllib.parse.quote_plus(translated_query)
            search_url = f"https://allegro.pl/listing?string={encoded_query}"

            logger.info(f"üîç HTTP –ø–æ–∏—Å–∫: {query} ‚Üí {translated_query}")

            # –£–ª—É—á—à–µ–Ω–Ω—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏ —Å —Ä–æ—Ç–∞—Ü–∏–µ–π
            user_agents = [
                'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
            ]

            headers = {
                'User-Agent': random.choice(user_agents),
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                'Accept-Language': 'pl-PL,pl;q=0.9,en;q=0.8',
                'Accept-Encoding': 'gzip, deflate, br',
                'Connection': 'keep-alive',
                'Upgrade-Insecure-Requests': '1',
                'Sec-Fetch-Dest': 'document',
                'Sec-Fetch-Mode': 'navigate',
                'Sec-Fetch-Site': 'none'
            }

            # –°–ª—É—á–∞–π–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞
            time.sleep(random.uniform(0.5, 2.0))

            session = requests.Session()
            session.headers.update(headers)

            response = session.get(search_url, timeout=15)

            if response.status_code == 403:
                logger.warning("403 –æ—à–∏–±–∫–∞, –ø—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π URL")
                # –ü—Ä–æ–±—É–µ–º –¥—Ä—É–≥–æ–π —Ñ–æ—Ä–º–∞—Ç URL
                alt_url = f"https://allegro.pl/kategoria/elektronika?string={encoded_query}"
                response = session.get(alt_url, timeout=15)

            response.raise_for_status()

            # –ü–∞—Ä—Å–∏–º HTML
            soup = BeautifulSoup(response.content, 'html.parser')

            # –ò—â–µ–º —Ç–æ–≤–∞—Ä—ã –ø–æ —Ä–∞–∑–ª–∏—á–Ω—ã–º —Å–µ–ª–µ–∫—Ç–æ—Ä–∞–º
            product_selectors = [
                'article[data-role="offer"]',
                'div[data-role="offer"]',
                'article[data-analytics-view-label]',
                '[data-testid="listing-item"]',
                'article',
                'div[class*="listing"]'
            ]

            found_products = []
            for selector in product_selectors:
                elements = soup.select(selector)
                if elements:
                    logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(elements)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Å —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–º: {selector}")
                    found_products = elements
                    break

            if not found_products:
                logger.warning("‚ö†Ô∏è –¢–æ–≤–∞—Ä—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –Ω–∏ —Å –æ–¥–Ω–∏–º —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–º")
                return products

            # –ü–∞—Ä—Å–∏–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã
            for i, element in enumerate(found_products[:20]):  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 20
                try:
                    # –ò—â–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
                    title = ""
                    title_selectors = ['a[href*="/oferta/"]', 'h3 a', 'h2 a', 'a[title]']
                    for title_sel in title_selectors:
                        title_elem = element.select_one(title_sel)
                        if title_elem:
                            title = title_elem.get('title') or title_elem.get_text(strip=True)
                            if title:
                                break

                    # –ò—â–µ–º —Ü–µ–Ω—É
                    price = ""
                    # BeautifulSoup –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç :contains, –ø–æ—ç—Ç–æ–º—É –∏—â–µ–º –ø–æ-–¥—Ä—É–≥–æ–º—É
                    price_elements = element.find_all(['span', 'div'], class_=re.compile(r'price', re.I))
                    for price_elem in price_elements:
                        price_text = price_elem.get_text(strip=True)
                        if 'z≈Ç' in price_text:
                            price = price_text
                            break

                    # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –ø–æ –∫–ª–∞—Å—Å—É, –∏—â–µ–º –ª—é–±–æ–π —ç–ª–µ–º–µ–Ω—Ç —Å "z≈Ç"
                    if not price:
                        all_elements = element.find_all(text=re.compile(r'z≈Ç'))
                        for elem in all_elements:
                            parent = elem.parent
                            if parent:
                                price_text = parent.get_text(strip=True)
                                if 'z≈Ç' in price_text:
                                    price = price_text
                                    break

                    # –ò—â–µ–º —Å—Å—ã–ª–∫—É
                    url = ""
                    link_elem = element.select_one('a[href*="/oferta/"]')
                    if link_elem:
                        url = link_elem.get('href')
                        if url and not url.startswith('http'):
                            url = f"https://allegro.pl{url}"

                    # –ò—â–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                    image = ""
                    img_elem = element.select_one('img')
                    if img_elem:
                        image = img_elem.get('src') or img_elem.get('data-src', '')

                    if title and price:
                        # –°—á–∏—Ç–∞–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å
                        score = self.calculate_relevance_score(title, query)

                        if score >= 25:  # –°–Ω–∏–∂–∞–µ–º –ø–æ—Ä–æ–≥ —Å 45 –¥–æ 25 –¥–ª—è –±–æ–ª—å—à–µ–≥–æ –æ—Ö–≤–∞—Ç–∞
                            product = {
                                'name': title,
                                'price': price,
                                'url': url,
                                'image': image,
                                'description': f"–ò—Å—Ç–æ—á–Ω–∏–∫: Allegro, –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {score}",
                                'relevance_score': score
                            }
                            products.append(product)
                            logger.info(f"Found matching product: {title[:50]}... (Score: {score})")
                        else:
                            logger.info(f"Skipping non-matching product: {title[:50]}... (Score: {score})")

                except Exception as e:
                    logger.debug(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ç–æ–≤–∞—Ä–∞ {i}: {e}")
                    continue

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ HTTP –ø–æ–∏—Å–∫–∞: {e}")

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        products.sort(key=lambda x: x.get('relevance_score', 0), reverse=True)
        logger.info(f"üèÅ HTTP –ø–æ–∏—Å–∫: –Ω–∞–π–¥–µ–Ω–æ {len(products)} —Ç–æ–≤–∞—Ä–æ–≤")

        return products

    async def search_products(self, query: str) -> List[Dict[str, Any]]:
        """
        –ü–æ–∏—Å–∫ —Ç–æ–≤–∞—Ä–æ–≤ –Ω–∞ Allegro
        """
        products = []

        try:
            async with async_playwright() as p:
                browser = await p.chromium.launch(
                    headless=True,  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º headless —Ä–µ–∂–∏–º
                    args=[
                        '--no-sandbox',
                        '--disable-dev-shm-usage'
                    ]
                )
                context = await browser.new_context(
                    user_agent='Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                    viewport={'width': 1920, 'height': 1080},
                    locale='pl-PL',
                    timezone_id='Europe/Warsaw'
                )
                
                # –î–æ–±–∞–≤–ª—è–µ–º JavaScript –¥–ª—è –æ–±—Ö–æ–¥–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏ –±–æ—Ç–æ–≤
                await context.add_init_script("""
                    Object.defineProperty(navigator, 'webdriver', {
                        get: () => undefined,
                    });
                    
                    window.chrome = {
                        runtime: {},
                    };
                    
                    Object.defineProperty(navigator, 'plugins', {
                        get: () => [1, 2, 3, 4, 5],
                    });
                """)
                
                page = await context.new_page()

                # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É –ø–æ–∏—Å–∫–∞
                search_url = f"https://allegro.pl/listing?string={query.replace(' ', '+')}"
                logger.info(f"üîç –ü–æ–∏—Å–∫: {search_url}")

                await page.goto(search_url, timeout=60000)  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –¥–æ 60 —Å–µ–∫—É–Ω–¥
                await page.wait_for_load_state("domcontentloaded")

                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º GDPR –±–æ–ª–µ–µ –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ
                gdpr_selectors = [
                    '[data-role="accept-consent"]',
                    'button[data-testid="consent-accept"]',
                    'button:has-text("Akceptujƒô")',
                    'button:has-text("Accept")',
                    'button:has-text("Zgadzam siƒô")'
                ]

                for gdpr_selector in gdpr_selectors:
                    try:
                        consent_button = page.locator(gdpr_selector)
                        if await consent_button.count() > 0:
                            await consent_button.click()
                            await asyncio.sleep(3)
                            logger.info(f"‚úÖ GDPR consent –ø—Ä–∏–Ω—è—Ç —Å —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–º: {gdpr_selector}")
                            break
                    except:
                        continue

                await page.wait_for_load_state("networkidle", timeout=30000)
                await asyncio.sleep(5)  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –æ–∂–∏–¥–∞–Ω–∏–µ

                # –ü–ê–£–ó–ê –î–õ–Ø –ü–†–û–°–ú–û–¢–†–ê –°–¢–†–ê–ù–ò–¶–´
                logger.info("üîç –ë–†–ê–£–ó–ï–† –û–¢–ö–†–´–¢! –ü–æ—Å–º–æ—Ç—Ä–∏—Ç–µ —á—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ...")

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∫–∞–ø—á–∏
                captcha_detected = await self.detect_captcha(page)
                if captcha_detected:
                    logger.warning("ü§ñ –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –∫–∞–ø—á–∞! –ü—ã—Ç–∞–µ–º—Å—è —Ä–µ—à–∏—Ç—å...")
                    captcha_solved = await self.solve_captcha_2captcha(page)
                    if captcha_solved:
                        logger.info("‚úÖ –ö–∞–ø—á–∞ —Ä–µ—à–µ–Ω–∞, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –ø–æ–∏—Å–∫...")
                        await asyncio.sleep(3)
                    else:
                        logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–µ—à–∏—Ç—å –∫–∞–ø—á—É –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏")
                        logger.info("‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ —Ä—É—á–Ω–æ–≥–æ —Ä–µ—à–µ–Ω–∏—è –∫–∞–ø—á–∏ (30 —Å–µ–∫—É–Ω–¥)...")
                        await asyncio.sleep(30)

                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—â–µ —Ä–∞–∑ –ø–æ—Å–ª–µ –æ–∂–∏–¥–∞–Ω–∏—è
                        if await self.detect_captcha(page):
                            logger.error("‚ùå –ö–∞–ø—á–∞ –≤—Å–µ –µ—â–µ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç, –ø—Ä–µ—Ä—ã–≤–∞–µ–º –ø–æ–∏—Å–∫")
                            return []
                        else:
                            logger.info("‚úÖ –ö–∞–ø—á–∞ —Ä–µ—à–µ–Ω–∞ –≤—Ä—É—á–Ω—É—é, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º")

                await asyncio.sleep(15)  # 15 —Å–µ–∫—É–Ω–¥ –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞

                # –î–æ–±–∞–≤–ª—è–µ–º –±–æ–ª–µ–µ –¥–µ—Ç–∞–ª—å–Ω—É—é –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫—É
                try:
                    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º, –∑–∞–≥—Ä—É–∑–∏–ª–∞—Å—å –ª–∏ —Å—Ç—Ä–∞–Ω–∏—Ü–∞
                    page_title = await page.title()
                    logger.info(f"üìÑ –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {page_title}")
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞
                    search_results = page.locator('div[data-testid="listing-container"]')
                    if await search_results.count() == 0:
                        logger.warning("‚ö†Ô∏è –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω")
                        
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ
                    all_elements = page.locator('*')
                    total_count = await all_elements.count()
                    logger.info(f"üìä –í—Å–µ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ: {total_count}")
                    
                    # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –ª—é–±—ã–µ —Ç–æ–≤–∞—Ä—ã
                    generic_selectors = ['article', 'div[data-role]', '[data-testid]']
                    for selector in generic_selectors:
                        count = await page.locator(selector).count()
                        logger.info(f"üîç –≠–ª–µ–º–µ–Ω—Ç–æ–≤ —Å —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–º '{selector}': {count}")
                        
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏: {e}")

                # –û–±–Ω–æ–≤–ª—è–µ–º —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ç–æ–≤–∞—Ä–æ–≤ - –¥–æ–±–∞–≤–ª—è–µ–º –±–æ–ª–µ–µ –æ–±—â–∏–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã
                selectors_to_try = [
                    'article[data-role="offer"]',
                    'div[data-role="offer"]',
                    'article[data-analytics-view-label]',
                    '[data-testid="listing-item"]',
                    'div[data-testid="web-listing-item"]',
                    'article[data-testid="listing-item"]',
                    'div[class*="listing-item"]',
                    'article[class*="offer"]',
                    'div[class*="offer-item"]',
                    'section[data-testid="listing-item"]',
                    # –î–æ–±–∞–≤–ª—è–µ–º –±–æ–ª–µ–µ –æ–±—â–∏–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã
                    'article',
                    'div[data-testid]',
                    '[data-testid*="item"]',
                    '[data-testid*="offer"]',
                    '[data-testid*="product"]',
                    'div[class*="item"]',
                    'section[class*="item"]'
                ]

                found_products = False

                for selector in selectors_to_try:
                    try:
                        elements = page.locator(selector)
                        count = await elements.count()

                        if count > 0:
                            logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {count} —Ç–æ–≤–∞—Ä–æ–≤ —Å —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–º: {selector}")
                            found_products = True

                            # –ü–∞—Ä—Å–∏–º —Ç–æ–≤–∞—Ä—ã
                            for i in range(min(count, 30)):
                                try:
                                    element = elements.nth(i)

                                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ - –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ –≥–∏–±–∫–∏–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã
                                    title = ""
                                    url = ""

                                    # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ —Å–ø–æ—Å–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏ —Å—Å—ã–ª–∫—É
                                    title_selectors = [
                                        'a[href*="/oferta/"]',
                                        'a[data-testid*="title"]',
                                        'a[data-testid*="name"]',
                                        'h3 a',
                                        'h2 a',
                                        'a[title]',
                                        'a'
                                    ]

                                    for title_selector in title_selectors:
                                        title_element = element.locator(title_selector).first
                                        if await title_element.count() > 0:
                                            title = await title_element.get_attribute('title') or await title_element.text_content()
                                            url = await title_element.get_attribute('href')
                                            if title and title.strip():
                                                break

                                    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ü–µ–Ω—É
                                    price = ""
                                    price_selectors = [
                                        # –û—Å–Ω–æ–≤–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã —Å –≤–∞–ª—é—Ç–æ–π
                                        'span:has-text("z≈Ç")',
                                        'div:has-text("z≈Ç")',
                                        '*:has-text("z≈Ç")',

                                        # Data-testid —Å–µ–ª–µ–∫—Ç–æ—Ä—ã
                                        '[data-testid*="price"]',
                                        '[data-testid*="Price"]',
                                        '[data-testid="price-container"]',
                                        '[data-testid="price"]',
                                        '[data-testid="price-label"]',
                                        '[data-testid="price-value"]',

                                        # –ö–ª–∞—Å—Å—ã —Ü–µ–Ω
                                        'span[class*="price"]',
                                        'div[class*="price"]',
                                        '[class*="_price"]',
                                        '[class*="amount"]',
                                        '[class*="cost"]',
                                        '.price',

                                        # Data-role —Å–µ–ª–µ–∫—Ç–æ—Ä—ã
                                        'span[data-role="price"]',
                                        '[data-role="price"]',

                                        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ
                                        'span:has-text("PLN")',
                                        'span:has-text(",")',
                                        '[aria-label*="price"]',
                                        '[aria-label*="cena"]',
                                        '.offer-price',
                                        '.product-price'
                                    ]

                                    for price_selector in price_selectors:
                                        price_element = element.locator(price_selector).first
                                        if await price_element.count() > 0:
                                            price = await price_element.text_content()
                                            if price and price.strip() and ('z≈Ç' in price or ',' in price):
                                                break

                                    # –ï—Å–ª–∏ —Ü–µ–Ω–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –ø–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –ª—é–±–æ–π —Ç–µ–∫—Å—Ç —Å —á–∏—Å–ª–æ–º –∏ z≈Ç
                                    if not price:
                                        all_text = await element.text_content()
                                        import re
                                        price_match = re.search(r'\d+[,.]?\d*\s*z≈Ç', all_text)
                                        if price_match:
                                            price = price_match.group()

                                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ - —É–ª—É—á—à–µ–Ω–Ω—ã–π –º–µ—Ç–æ–¥
                                    image = ""
                                    image_selectors = [
                                        'img[src*="allegro"]',
                                        'img[data-src*="allegro"]',
                                        'img[src]',
                                        'img[data-src]',
                                        'img[data-lazy-src]'
                                    ]

                                    for img_selector in image_selectors:
                                        img_element = element.locator(img_selector).first
                                        if await img_element.count() > 0:
                                            src = await img_element.get_attribute('src') or await img_element.get_attribute('data-src') or await img_element.get_attribute('data-lazy-src')
                                            if src:
                                                # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–ª–Ω—É—é —Å—Å—ã–ª–∫—É
                                                if src.startswith('//'):
                                                    image = f"https:{src}"
                                                elif src.startswith('/'):
                                                    image = f"https://allegro.pl{src}"
                                                else:
                                                    image = src

                                                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ –Ω–µ –∏–∫–æ–Ω–∫–∞
                                                if not any(x in image.lower() for x in ['icon', 'logo', 'sprite']) or 'product' in image.lower():
                                                    break

                                    if not image:
                                        # Fallback - –ª—é–±–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                                        img_element = element.locator('img').first
                                        if await img_element.count() > 0:
                                            src = await img_element.get_attribute('src')
                                            if src:
                                                image = src if src.startswith('http') else f"https://allegro.pl{src}"

                                    if title and price:
                                        title = title.strip()
                                        price = price.strip()

                                        # –°—á–∏—Ç–∞–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å
                                        score = self.calculate_relevance_score(title, query)

                                        logger.info(f"üì¶ {i+1}. {title[:70]}... | {price} | Score: {score}")

                                        if score >= 25:  # –°–Ω–∏–∂–∞–µ–º –ø–æ—Ä–æ–≥ —Å 45 –¥–æ 25 –¥–ª—è –±–æ–ª—å—à–µ–≥–æ –æ—Ö–≤–∞—Ç–∞
                                            # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º URL
                                            if url and not url.startswith('http'):
                                                if url.startswith('/'):
                                                    url = f"https://allegro.pl{url}"
                                                else:
                                                    url = f"https://allegro.pl/{url}"
                                            elif not url:
                                                # –ï—Å–ª–∏ URL –Ω–µ –Ω–∞–π–¥–µ–Ω, —Å–æ–∑–¥–∞–µ–º –ø–æ–∏—Å–∫–æ–≤—É—é —Å—Å—ã–ª–∫—É
                                                url = f"https://allegro.pl/listing?string={query.replace(' ', '+')}"

                                            product = {
                                                'name': title,
                                                'price': price if price else "–¶–µ–Ω–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞",
                                                'url': url,
                                                'image': image,
                                                'description': f"–ò—Å—Ç–æ—á–Ω–∏–∫: Allegro, –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {score}",
                                                'relevance_score': score
                                            }
                                            products.append(product)
                                            logger.info(f"Found matching product: {title[:50]}... (Score: {score})")
                                        else:
                                            logger.info(f"Skipping non-matching product: {title[:50]}... (Score: {score} < 25)")

                                except Exception as e:
                                    logger.debug(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ç–æ–≤–∞—Ä–∞ {i}: {e}")
                                    continue

                            break  # –í—ã—Ö–æ–¥–∏–º –∏–∑ —Ü–∏–∫–ª–∞ –µ—Å–ª–∏ –Ω–∞—à–ª–∏ —Ç–æ–≤–∞—Ä—ã

                    except Exception as e:
                        logger.debug(f"–°–µ–ª–µ–∫—Ç–æ—Ä {selector} –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {e}")
                        continue

                if not found_products:
                    logger.error("‚ùå –¢–æ–≤–∞—Ä—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –Ω–∏ —Å –æ–¥–Ω–∏–º —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–º")

                    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ - –ø–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –ª—é–±—ã–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ —Ç–æ–≤–∞—Ä—ã
                    try:
                        all_links = page.locator('a[href*="oferta"]')
                        links_count = await all_links.count()
                        logger.info(f"üîó –ù–∞–π–¥–µ–Ω–æ —Å—Å—ã–ª–æ–∫ –Ω–∞ —Ç–æ–≤–∞—Ä—ã: {links_count}")

                        if links_count > 0:
                            # –ü–æ–ø—Ä–æ–±—É–µ–º –∏–∑–≤–ª–µ—á—å –¥–∞–Ω–Ω—ã–µ –∏–∑ –ø–µ—Ä–≤—ã—Ö –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å—Å—ã–ª–æ–∫
                            for i in range(min(links_count, 5)):
                                try:
                                    link = all_links.nth(i)
                                    title = await link.get_attribute('title') or await link.text_content()
                                    url = await link.get_attribute('href')

                                    if title and title.strip():
                                        score = self.calculate_relevance_score(title.strip(), query)
                                        logger.info(f"üîó –ù–∞–π–¥–µ–Ω–∞ —Å—Å—ã–ª–∫–∞: {title[:50]}... (Score: {score})")

                                        if score >= 45:
                                            # –ü–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —Ü–µ–Ω—É —Ä—è–¥–æ–º —Å —ç—Ç–æ–π —Å—Å—ã–ª–∫–æ–π
                                            parent = link.locator('xpath=..')
                                            price_element = parent.locator('span:has-text("z≈Ç")').first
                                            price = await price_element.text_content() if await price_element.count() > 0 else "–¶–µ–Ω–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞"

                                            # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º URL
                                            if url and not url.startswith('http'):
                                                if url.startswith('/'):
                                                    url = f"https://allegro.pl{url}"
                                                else:
                                                    url = f"https://allegro.pl/{url}"
                                            elif not url:
                                                # –ï—Å–ª–∏ URL –Ω–µ –Ω–∞–π–¥–µ–Ω, —Å–æ–∑–¥–∞–µ–º –ø–æ–∏—Å–∫–æ–≤—É—é —Å—Å—ã–ª–∫—É
                                                url = f"https://allegro.pl/listing?string={query.replace(' ', '+')}"

                                            product = {
                                                'name': title.strip(),
                                                'price': price.strip() if price else "–¶–µ–Ω–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞",
                                                'url': url,
                                                'image': "",
                                                'description': f"–ò—Å—Ç–æ—á–Ω–∏–∫: Allegro, –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {score}",
                                                'relevance_score': score
                                            }
                                            products.append(product)
                                            logger.info(f"‚úÖ –¢–æ–≤–∞—Ä –¥–æ–±–∞–≤–ª–µ–Ω —á–µ—Ä–µ–∑ —Ä–µ–∑–µ—Ä–≤–Ω—ã–π –º–µ—Ç–æ–¥!")

                                except Exception as e:
                                    logger.debug(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Å—ã–ª–∫–∏ {i}: {e}")
                                    continue

                    except Exception as e:
                        logger.debug(f"–û—à–∏–±–∫–∞ —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞: {e}")

                await browser.close()

        except Exception as e:
            logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        products.sort(key=lambda x: x.get('relevance_score', 0), reverse=True)

        logger.info(f"üèÅ –ù–∞–π–¥–µ–Ω–æ {len(products)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤")
        return products

    def search_mobile_version(self, query: str) -> List[Dict[str, Any]]:
        """–ü–æ–∏—Å–∫ —á–µ—Ä–µ–∑ –º–æ–±–∏–ª—å–Ω—É—é –≤–µ—Ä—Å–∏—é Allegro"""
        try:
            import urllib.parse
            encoded_query = urllib.parse.quote_plus(query)
            mobile_url = f"https://m.allegro.pl/listing?string={encoded_query}"

            mobile_headers = {
                'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 15_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.0 Mobile/15E148 Safari/604.1',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                'Accept-Language': 'pl-PL,pl;q=0.9'
            }

            response = requests.get(mobile_url, headers=mobile_headers, timeout=10)

            if response.status_code == 200:
                return self.parse_simple_html(response.text, query)

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –º–æ–±–∏–ª—å–Ω–æ–π –≤–µ—Ä—Å–∏–∏: {e}")

        return []

    def search_by_categories(self, query: str) -> List[Dict[str, Any]]:
        """–ü–æ–∏—Å–∫ —á–µ—Ä–µ–∑ –æ—Å–Ω–æ–≤–Ω—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏"""
        categories = {
            'elektronika': ['—Ç–µ–ª–µ—Ñ–æ–Ω', '—Å–º–∞—Ä—Ç—Ñ–æ–Ω', '–∞–π—Ñ–æ–Ω', '–Ω–æ—É—Ç–±—É–∫', '–∫–æ–º–ø—å—é—Ç–µ—Ä', '–ø–ª–∞–Ω—à–µ—Ç'],
            'dom-i-ogrod': ['–∫–æ—Ñ–µ–º–∞—à–∏–Ω–∞', '–ø—ã–ª–µ—Å–æ—Å', '—Ö–æ–ª–æ–¥–∏–ª—å–Ω–∏–∫', '–º–µ–±–µ–ª—å'],
            'moda': ['–∫—Ä–æ—Å—Å–æ–≤–∫–∏', '–∫—É—Ä—Ç–∫–∞', '–¥–∂–∏–Ω—Å—ã', '—Ñ—É—Ç–±–æ–ª–∫–∞'],
            'sport-i-turystyka': ['–≤–µ–ª–æ—Å–∏–ø–µ–¥', '–ª—ã–∂–∏', '—Ñ–∏—Ç–Ω–µ—Å']
        }

        query_lower = query.lower()
        selected_category = 'elektronika'  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
        for category, keywords in categories.items():
            if any(keyword in query_lower for keyword in keywords):
                selected_category = category
                break

        try:
            import urllib.parse
            encoded_query = urllib.parse.quote_plus(query)
            category_url = f"https://allegro.pl/kategoria/{selected_category}?string={encoded_query}"

            response = requests.get(category_url, headers=self.headers, timeout=10)

            if response.status_code == 200:
                return self.parse_simple_html(response.text, query)

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º: {e}")

        return []

    def parse_simple_html(self, html: str, query: str) -> List[Dict[str, Any]]:
        """–ü—Ä–æ—Å—Ç–æ–π –ø–∞—Ä—Å–∏–Ω–≥ HTML —Å –±–∞–∑–æ–≤—ã–º –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ–º —Ü–µ–Ω –∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π"""
        try:
            from bs4 import BeautifulSoup
            soup = BeautifulSoup(html, 'html.parser')
            products = []

            # –ò—â–µ–º —Å—Å—ã–ª–∫–∏ –Ω–∞ —Ç–æ–≤–∞—Ä—ã (–ø—Ä–æ—Å—Ç–æ–π –º–µ—Ç–æ–¥, –∫–æ—Ç–æ—Ä—ã–π —Ä–∞–±–æ—Ç–∞–ª)
            links = soup.find_all('a', href=True)

            for link in links:
                href = link.get('href', '')
                if '/oferta/' in href:
                    title = link.get_text(strip=True)
                    if title and len(title) > 10:
                        score = self.calculate_relevance_score(title, query)
                        if score >= 30:
                            # –ò—â–µ–º —Ü–µ–Ω—É —Ä—è–¥–æ–º —Å —Ç–æ–≤–∞—Ä–æ–º - —É–ª—É—á—à–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫
                            price = "–¶–µ–Ω–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞"
                            parent = link.find_parent()

                            # –†–∞—Å—à–∏—Ä—è–µ–º –ø–æ–∏—Å–∫ –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ —É—Ä–æ–≤–Ω–µ–π –≤–≤–µ—Ä—Ö
                            search_containers = [parent]
                            if parent:
                                # –î–æ–±–∞–≤–ª—è–µ–º —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã
                                grandparent = parent.find_parent()
                                if grandparent:
                                    search_containers.append(grandparent)
                                    great_grandparent = grandparent.find_parent()
                                    if great_grandparent:
                                        search_containers.append(great_grandparent)

                            for container in search_containers:
                                if not container:
                                    continue

                                # –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º –ø–æ —Å–µ–ª–µ–∫—Ç–æ—Ä–∞–º
                                price_selectors = [
                                    '[data-testid*="price"]',
                                    '[class*="price"]',
                                    '[class*="amount"]',
                                    '[class*="cost"]',
                                    '.price'
                                ]

                                for selector in price_selectors:
                                    price_elem = container.select_one(selector)
                                    if price_elem:
                                        price_text = price_elem.get_text(strip=True)
                                        if price_text and 'z≈Ç' in price_text:
                                            price = price_text
                                            break

                                if price != "–¶–µ–Ω–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞":
                                    break

                                # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –ø–æ —Å–µ–ª–µ–∫—Ç–æ—Ä–∞–º, –∏—â–µ–º —Ä–µ–≥—É–ª—è—Ä–Ω—ã–º–∏ –≤—ã—Ä–∞–∂–µ–Ω–∏—è–º–∏
                                price_text = container.get_text()
                                import re

                                # –£–ª—É—á—à–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ü–µ–Ω
                                price_patterns = [
                                    r'\d+[,\s]*\d*\s*z≈Ç',  # 123 z≈Ç –∏–ª–∏ 123,45 z≈Ç
                                    r'\d+[,\.]\d{2}\s*z≈Ç',  # 123.45 z≈Ç –∏–ª–∏ 123,45 z≈Ç
                                    r'\d+\s*z≈Ç',           # 123z≈Ç
                                    r'\d+[,\s]*\d*\s*PLN', # 123 PLN
                                ]

                                for pattern in price_patterns:
                                    price_match = re.search(pattern, price_text)
                                    if price_match:
                                        price = price_match.group().strip()
                                        break

                                if price != "–¶–µ–Ω–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞":
                                    break

                            # –ò—â–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ - —É–ª—É—á—à–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫
                            image = ""

                            # –ò—â–µ–º –≤ —Ç–µ—Ö –∂–µ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞—Ö —á—Ç–æ –∏ —Ü–µ–Ω—É
                            for container in search_containers:
                                if not container:
                                    continue

                                # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
                                img_selectors = [
                                    'img[src*="allegro"]',
                                    'img[data-src*="allegro"]',
                                    'img[data-lazy-src*="allegro"]',
                                    'img[src*="product"]',
                                    'img[data-src*="product"]',
                                    'img[src]',
                                    'img[data-src]',
                                    'img[data-lazy-src]'
                                ]

                                for selector in img_selectors:
                                    img_elem = container.select_one(selector)
                                    if img_elem:
                                        src = (img_elem.get('src') or
                                              img_elem.get('data-src') or
                                              img_elem.get('data-lazy-src') or
                                              img_elem.get('data-original'))

                                        if src:
                                            # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–ª–Ω—É—é —Å—Å—ã–ª–∫—É
                                            if src.startswith('//'):
                                                image = f"https:{src}"
                                            elif src.startswith('/'):
                                                image = f"https://allegro.pl{src}"
                                            else:
                                                image = src

                                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ –Ω–µ –∏–∫–æ–Ω–∫–∞ –∏–ª–∏ –ª–æ–≥–æ—Ç–∏–ø
                                            if not any(x in image.lower() for x in ['icon', 'logo', 'sprite', 'placeholder']) or 'product' in image.lower():
                                                break

                                if image:
                                    break

                            # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–ª–Ω—É—é —Å—Å—ã–ª–∫—É
                            if not href.startswith('http'):
                                href = f"https://allegro.pl{href}"

                            product = {
                                'name': title,
                                'price': price,
                                'url': href,
                                'image': image,
                                'description': title,
                                'relevance_score': score
                            }
                            products.append(product)

                            if len(products) >= 10:
                                break

            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
            if products:
                products.sort(key=lambda x: x.get('relevance_score', 0), reverse=True)
                logger.info(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏")

            logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(products)} —Ç–æ–≤–∞—Ä–æ–≤ —á–µ—Ä–µ–∑ –ø—Ä–æ—Å—Ç–æ–π –ø–∞—Ä—Å–∏–Ω–≥")
            return products

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ HTML: {e}")
            return []


# –°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±–µ—Ä—Ç–∫–∞
def search_allegro_improved(query: str, max_pages: int = 1, debug_mode: bool = False) -> List[Dict[str, Any]]:
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–∏—Å–∫–∞ –Ω–∞ Allegro
    """
    try:
        # –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä —Å–∫—Ä–∞–ø–µ—Ä–∞
        scraper = AllegroScraper()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ–∫—É—â–∏–π IP
        current_ip = scraper.get_current_ip()
        logger.info(f"üåê –¢–µ–∫—É—â–∏–π IP: {current_ip}")

        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –ø—Ä–æ—Å—Ç–æ–π HTTP –ø–æ–∏—Å–∫ —Å —Ä–∞–∑–Ω—ã–º–∏ User-Agent
        logger.info(f"üîç –ü–æ–ø—ã—Ç–∫–∞ HTTP –ø–æ–∏—Å–∫–∞ –Ω–∞ Allegro: {query}")
        
        # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ User-Agent –¥–ª—è –æ–±—Ö–æ–¥–∞ –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫
        user_agents = [
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (iPhone; CPU iPhone OS 17_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Mobile/15E148 Safari/604.1'
        ]
        
        for i, user_agent in enumerate(user_agents):
            try:
                logger.info(f"üîç –ü–æ–ø—ã—Ç–∫–∞ {i+1}/4 —Å User-Agent: {user_agent[:50]}...")
                scraper.headers['User-Agent'] = user_agent
                http_results = scraper.search_products_simple(query)
                
                if http_results and len(http_results) > 0:
                    logger.info(f"‚úÖ HTTP –ø–æ–∏—Å–∫ —É—Å–ø–µ—à–µ–Ω —Å User-Agent {i+1}: –Ω–∞–π–¥–µ–Ω–æ {len(http_results)} —Ç–æ–≤–∞—Ä–æ–≤")
                    return http_results
                    
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ HTTP –ø–æ–∏—Å–∫–∞ —Å User-Agent {i+1}: {e}")
                continue

        logger.info("‚ö†Ô∏è HTTP –ø–æ–∏—Å–∫ –Ω–µ –¥–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤, –ø—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –º–µ—Ç–æ–¥—ã...")

        # –ú–µ—Ç–æ–¥ 2: –ü–æ–∏—Å–∫ —á–µ—Ä–µ–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –±–µ–∑ CAPTCHA
        try:
            logger.info("üîç –ü—Ä–æ–±—É–µ–º –ø–æ–∏—Å–∫ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º...")
            category_results = scraper.search_by_categories(query)
            if category_results and len(category_results) > 0:
                logger.info(f"‚úÖ –ü–æ–∏—Å–∫ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º: –Ω–∞–π–¥–µ–Ω–æ {len(category_results)} —Ç–æ–≤–∞—Ä–æ–≤")
                return category_results
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º: {e}")

        # –ú–µ—Ç–æ–¥ 3: –ú–æ–±–∏–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è
        try:
            logger.info("üîç –ü—Ä–æ–±—É–µ–º –º–æ–±–∏–ª—å–Ω—É—é –≤–µ—Ä—Å–∏—é...")
            mobile_results = scraper.search_mobile_version(query)
            if mobile_results and len(mobile_results) > 0:
                logger.info(f"‚úÖ –ú–æ–±–∏–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è: –Ω–∞–π–¥–µ–Ω–æ {len(mobile_results)} —Ç–æ–≤–∞—Ä–æ–≤")
                return mobile_results
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –º–æ–±–∏–ª—å–Ω–æ–π –≤–µ—Ä—Å–∏–∏: {e}")

        # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–æ, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –≤–º–µ—Å—Ç–æ fallback
        logger.warning("‚ùå –í—Å–µ –º–µ—Ç–æ–¥—ã –ø–æ–∏—Å–∫–∞ Allegro –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∏, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫")
        return []

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ search_allegro_improved: {e}")
        return []

# –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ª–∏—Å—Ç–∏–Ω–≥–æ–≤ (—É–ø—Ä–æ—â–µ–Ω–Ω—ã–µ)
def generate_product_description(product_name: str, price: str) -> str:
    name_lower = product_name.lower()

    if any(word in name_lower for word in ['macbook', 'laptop', 'notebook']):
        return f"{product_name}\n\n‚úÖ Profesjonalny Laptop\n\nWydajny komputer przeno≈õny idealny do pracy, nauki i rozrywki."
    elif any(word in name_lower for word in ['iphone', 'samsung', 'xiaomi']):
        return f"{product_name}\n\n‚úÖ Wysokiej Jako≈õci Smartfon\n\nIdealny telefon kom√≥rkowy z najnowszymi funkcjami."
    else:
        return f"{product_name}\n\n‚úÖ Wysokiej Jako≈õci Produkt\n\nProfesjonalny produkt najwy≈ºszej jako≈õci."

def generate_product_parameters(product_name: str) -> Dict[str, str]:
    return {
        'Stan': 'Nowy',
        'Faktura': 'Wystawiam fakturƒô VAT',
        'Marka': 'Oryginalna'
    }

def determine_category(product_name: str) -> str:
    name_lower = product_name.lower()
    if any(word in name_lower for word in ['macbook', 'laptop', 'notebook']):
        return 'Komputery'
    return 'Elektronika'

def generate_tags(product_name: str) -> List[str]:
    return ['nowy', 'oryginalny', 'gwarancja']

def generate_highlights(product_name: str) -> List[str]:
    return ['‚úÖ Nowy produkt', '‚úÖ Pe≈Çna gwarancja']

def generate_features(product_name: str) -> List[str]:
    return ['Oryginalny produkt', 'Pe≈Çna gwarancja']

def create_full_allegro_listing(product_data: Dict[str, Any]) -> Dict[str, Any]:
    """–°–æ–∑–¥–∞–µ—Ç —à–∞–±–ª–æ–Ω –æ–±—ä—è–≤–ª–µ–Ω–∏—è –¥–ª—è Allegro"""
    product_name = product_data.get('name', '')
    price = product_data.get('price', '')

    return {
        'title': product_name,
        'price': price,
        'description': generate_product_description(product_name, price),
        'parameters': generate_product_parameters(product_name),
        'images': [product_data.get('image', '')],
        'category': determine_category(product_name),
        'condition': 'Nowy',
        'warranty': 'Gwarancja producenta',
        'shipping': 'Darmowa dostawa',
        'payment': 'Przelew online, Pobranie',
        'tags': generate_tags(product_name),
        'highlights': generate_highlights(product_name),
        'features': generate_features(product_name)
    }

# –¢–µ—Å—Ç
async def test_search():
    scraper = AllegroScraper()
    results = await scraper.search_products("macbook m4 pro")

    print(f"\n –ù–∞–π–¥–µ–Ω–æ —Ç–æ–≤–∞—Ä–æ–≤: {len(results)}")
    for i, product in enumerate(results[:5]):
        print(f"{i+1}. {product['name'][:60]}...")
        print(f"   –¶–µ–Ω–∞: {product['price']}")
        print(f"   –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {product['relevance_score']}")
        print()

if __name__ == "__main__":
    asyncio.run(test_search())
