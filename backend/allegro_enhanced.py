
import asyncio
import logging
import os
import random
import time
import json
from typing import List, Dict, Any, Optional
from playwright.async_api import async_playwright, Page, Browser, BrowserContext
from dotenv import load_dotenv
import requests
from urllib.parse import quote_plus, urlencode

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class AllegroEnhancedScraper:
    """
    –£–ª—É—á—à–µ–Ω–Ω—ã–π —Å–∫—Ä–∞–ø–µ—Ä –¥–ª—è Allegro.pl —Å –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–º –æ–±—Ö–æ–¥–æ–º –∑–∞—â–∏—Ç—ã
    """
    
    def __init__(self):
        self.base_url = "https://allegro.pl"
        self.search_url = "https://allegro.pl/listing"
        self.mobile_url = "https://m.allegro.pl/listing"
        
        # –†–æ—Ç–∞—Ü–∏—è User-Agent'–æ–≤
        self.user_agents = [
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:121.0) Gecko/20100101 Firefox/121.0'
        ]
        
        # –°–ø–∏—Å–æ–∫ –ø—Ä–æ–∫—Å–∏ (–±—É–¥–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω –∏–∑ —Ñ–∞–π–ª–∞ –∏–ª–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è)
        self.proxy_list = self._load_proxy_list()
        
    def _load_proxy_list(self) -> List[str]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –ø—Ä–æ–∫—Å–∏ –∏–∑ —Ñ–∞–π–ª–∞ –∏–ª–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è"""
        proxies = []
        
        # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
        proxy_server = os.getenv('PROXY_SERVER')
        if proxy_server:
            proxies.append(proxy_server)
            logger.info(f"üåê –ó–∞–≥—Ä—É–∂–µ–Ω –ø—Ä–æ–∫—Å–∏ –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è: {proxy_server}")
        
        # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑ —Ñ–∞–π–ª–∞
        try:
            proxy_file = os.path.join(os.path.dirname(__file__), 'proxy_list.txt')
            if os.path.exists(proxy_file):
                with open(proxy_file, 'r') as f:
                    file_proxies = [
                        line.strip() for line in f.readlines()
                        if line.strip() and not line.strip().startswith('#')
                    ]
                    proxies.extend(file_proxies)
                    logger.info(f"üåê –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(file_proxies)} –ø—Ä–æ–∫—Å–∏ –∏–∑ —Ñ–∞–π–ª–∞")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–æ–∫—Å–∏ –∏–∑ —Ñ–∞–π–ª–∞: {e}")
        
        if not proxies:
            logger.info("üåê –ü—Ä–æ–∫—Å–∏ –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã, –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä—è–º–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ")
        
        return proxies
    
    def _get_random_proxy(self) -> Optional[Dict[str, str]]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª—É—á–∞–π–Ω—ã–π –ø—Ä–æ–∫—Å–∏ –∏–∑ —Å–ø–∏—Å–∫–∞"""
        if not self.proxy_list:
            return None
            
        proxy_server = random.choice(self.proxy_list)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–æ—Ä–º–∞—Ç –ø—Ä–æ–∫—Å–∏
        if not proxy_server.startswith('http'):
            proxy_server = f"http://{proxy_server}"
        
        proxy_config = {'server': proxy_server}
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—é –µ—Å–ª–∏ –µ—Å—Ç—å
        proxy_username = os.getenv('PROXY_USERNAME')
        proxy_password = os.getenv('PROXY_PASSWORD')
        
        if proxy_username and proxy_password:
            proxy_config['username'] = proxy_username
            proxy_config['password'] = proxy_password
        
        return proxy_config
    
    def _get_random_user_agent(self) -> str:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª—É—á–∞–π–Ω—ã–π User-Agent"""
        return random.choice(self.user_agents)
    
    async def _human_like_behavior(self, page: Page):
        """–ò–º–∏—Ç–∏—Ä—É–µ—Ç —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ"""
        try:
            # –°–ª—É—á–∞–π–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –ø–µ—Ä–µ–¥ –¥–µ–π—Å—Ç–≤–∏—è–º–∏
            await asyncio.sleep(random.uniform(1.0, 3.0))
            
            # –°–ª—É—á–∞–π–Ω–æ–µ –¥–≤–∏–∂–µ–Ω–∏–µ –º—ã—à–∏
            await page.mouse.move(
                random.randint(100, 800), 
                random.randint(100, 600)
            )
            
            # –°–ª—É—á–∞–π–Ω—ã–π —Å–∫—Ä–æ–ª–ª
            scroll_distance = random.randint(200, 800)
            await page.evaluate(f"window.scrollBy(0, {scroll_distance})")
            await asyncio.sleep(random.uniform(0.5, 1.5))
            
            # –ï—â–µ –æ–¥–∏–Ω —Å–∫—Ä–æ–ª–ª –Ω–∞–∑–∞–¥
            await page.evaluate(f"window.scrollBy(0, -{scroll_distance // 2})")
            await asyncio.sleep(random.uniform(0.5, 1.0))
            
            logger.debug("ü§ñ –í—ã–ø–æ–ª–Ω–µ–Ω–æ —á–µ–ª–æ–≤–µ–∫–æ-–ø–æ–¥–æ–±–Ω–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ")
            
        except Exception as e:
            logger.debug(f"–û—à–∏–±–∫–∞ –∏–º–∏—Ç–∞—Ü–∏–∏ –ø–æ–≤–µ–¥–µ–Ω–∏—è: {e}")
    
    async def _handle_gdpr_consent(self, page: Page) -> bool:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç GDPR —Å–æ–≥–ª–∞—Å–∏–µ"""
        try:
            gdpr_selectors = [
                '[data-role="accept-consent"]',
                'button[data-testid="consent-accept"]',
                'button:has-text("Akceptujƒô")',
                'button:has-text("Accept")',
                'button:has-text("Zgadzam siƒô")',
                'button:has-text("Zgoda")',
                '#onetrust-accept-btn-handler',
                '.ot-sdk-show-settings'
            ]
            
            for selector in gdpr_selectors:
                try:
                    consent_button = page.locator(selector).first
                    if await consent_button.count() > 0 and await consent_button.is_visible():
                        await consent_button.click()
                        await asyncio.sleep(2)
                        logger.info(f"‚úÖ GDPR —Å–æ–≥–ª–∞—Å–∏–µ –ø—Ä–∏–Ω—è—Ç–æ: {selector}")
                        return True
                except Exception as e:
                    logger.debug(f"–°–µ–ª–µ–∫—Ç–æ—Ä {selector} –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {e}")
                    continue
            
            return False
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ GDPR: {e}")
            return False
    
    async def _detect_captcha(self, page: Page) -> bool:
        """–û–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ—Ç –Ω–∞–ª–∏—á–∏–µ CAPTCHA –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ"""
        try:
            # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞
            search_indicators = [
                'text="ofert"',
                'text="sortowanie"',
                'text="trafno≈õƒá"',
                'a[href*="/oferta/"]',
                'article[data-role="offer"]',
                'div[data-testid="listing-container"]'
            ]
            
            for indicator in search_indicators:
                try:
                    element = page.locator(indicator).first
                    if await element.count() > 0:
                        logger.debug(f"‚úÖ –ù–∞–π–¥–µ–Ω—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞: {indicator}")
                        return False  # –ï—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã = –Ω–µ—Ç CAPTCHA
                except:
                    continue
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ CAPTCHA
            captcha_selectors = [
                'iframe[src*="captcha"]',
                'div[class*="captcha"]',
                'img[src*="captcha"]',
                '[data-testid*="captcha"]',
                'form[action*="captcha"]',
                '.g-recaptcha',
                '#captcha',
                'text="Przepisz kod z obrazka"',
                'text="Aplikacja przekroczy≈Ça limit"',
                'text="POTWIERD≈π"',
                'text="Potwierd≈∫, ≈ºe jeste≈õ cz≈Çowiekiem"',
                'text="Zauwa≈ºyli≈õmy nietypowe dzia≈Çanie"',
                'button:has-text("potwierdzam")',
                'button:has-text("Potwierd≈∫")',
                'text="potwierdzam"'
            ]
            
            for selector in captcha_selectors:
                try:
                    element = page.locator(selector).first
                    if await element.count() > 0:
                        logger.warning(f"ü§ñ –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ CAPTCHA: {selector}")
                        return True
                except:
                    continue
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            page_content = await page.content()
            captcha_keywords = [
                'captcha', 'Przepisz kod', 'przekroczy≈Ça limit',
                'Kod b≈Çƒôdu', 'POTWIERD≈π', 'limit zapyta≈Ñ'
            ]
            
            for keyword in captcha_keywords:
                if keyword.lower() in page_content.lower():
                    logger.warning(f"ü§ñ CAPTCHA –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –ø–æ –∫–ª—é—á–µ–≤–æ–º—É —Å–ª–æ–≤—É: {keyword}")
                    return True
            
            return False
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è CAPTCHA: {e}")
            return False
    
    async def _solve_captcha(self, page: Page) -> bool:
        """–†–µ—à–∞–µ—Ç CAPTCHA –∏—Å–ø–æ–ª—å–∑—É—è 2captcha —Å–µ—Ä–≤–∏—Å"""
        try:
            # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–æ—Å—Ç—É—é –∫–Ω–æ–ø–∫—É –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è
            logger.info("üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –ø—Ä–æ—Å—Ç–æ–π –∫–Ω–æ–ø–∫–∏ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è...")

            simple_confirm_buttons = [
                'button:has-text("potwierdzam")',
                'button:has-text("Potwierd≈∫")',
                'button:has-text("Confirm")',
                'input[value*="potwierdzam"]',
                'input[value*="Potwierd≈∫"]',
                '[role="button"]:has-text("potwierdzam")',
                'a:has-text("potwierdzam")',
                'button[class*="confirm"]',
                'button[class*="accept"]',
                'input[type="submit"]'
            ]

            for selector in simple_confirm_buttons:
                try:
                    button = page.locator(selector).first
                    if await button.count() > 0:
                        logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–∞ –∫–Ω–æ–ø–∫–∞ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è: {selector}")
                        logger.info("üñ±Ô∏è –ù–∞–∂–∏–º–∞–µ–º –∫–Ω–æ–ø–∫—É –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è...")

                        # –ò–º–∏—Ç–∏—Ä—É–µ–º —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ
                        await button.hover()
                        await asyncio.sleep(0.5)
                        await button.click()
                        await asyncio.sleep(2)

                        logger.info("‚úÖ –ö–Ω–æ–ø–∫–∞ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –Ω–∞–∂–∞—Ç–∞!")
                        return True
                except Exception as e:
                    logger.debug(f"–ö–Ω–æ–ø–∫–∞ {selector} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {e}")
                    continue

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º API –∫–ª—é—á –¥–ª—è 2captcha
            api_key = os.getenv('CAPTCHA_API_KEY', '9ed0ef51badf9a017ac50aea413d8001')  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –∫–ª—é—á
            if not api_key:
                logger.warning("‚ö†Ô∏è CAPTCHA_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")
                logger.info("üí° –î–æ–±–∞–≤—å—Ç–µ CAPTCHA_API_KEY –≤ .env —Ñ–∞–π–ª –∏–ª–∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è")
                logger.info("üí° –ü—Ä–∏–º–µ—Ä: CAPTCHA_API_KEY=your_2captcha_api_key_here")
                return False

            logger.info(f"üîë –ò—Å–ø–æ–ª—å–∑—É–µ–º 2captcha API –∫–ª—é—á: {api_key[:10]}...")
            logger.info("ü§ñ –ü—ã—Ç–∞–µ–º—Å—è —Ä–µ—à–∏—Ç—å CAPTCHA –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏...")

            # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
            current_url = page.url
            page_title = await page.title()
            logger.info(f"üåê URL —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å CAPTCHA: {current_url}")
            logger.info(f"üìÑ –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {page_title}")

            # –î–µ–ª–∞–µ–º —Å–∫—Ä–∏–Ω—à–æ—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å CAPTCHA
            screenshot_path = os.path.join(os.path.dirname(__file__), 'captcha_screenshot.png')
            await page.screenshot(path=screenshot_path, full_page=True)
            logger.info(f"üì∏ –°–∫—Ä–∏–Ω—à–æ—Ç CAPTCHA —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {screenshot_path}")

            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            page_content = await page.content()
            logger.info(f"üìù –†–∞–∑–º–µ—Ä —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {len(page_content)} —Å–∏–º–≤–æ–ª–æ–≤")

            # –ò—â–µ–º —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã CAPTCHA –Ω–∞ Allegro
            allegro_captcha_indicators = [
                'cloudflare', 'cf-challenge', 'challenge-form',
                'Sprawdzanie przeglƒÖdarki', 'Checking your browser',
                'DDoS protection', 'Ray ID'
            ]

            for indicator in allegro_captcha_indicators:
                if indicator.lower() in page_content.lower():
                    logger.info(f"üîç –û–±–Ω–∞—Ä—É–∂–µ–Ω –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä: {indicator}")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ Cloudflare challenge
            if 'cloudflare' in page_content.lower() or 'cf-challenge' in page_content.lower():
                logger.info("‚òÅÔ∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ Cloudflare –∑–∞—â–∏—Ç–∞")
                return await self._handle_cloudflare_challenge(page)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –ø–æ–ª—å—Å–∫–∏–µ CAPTCHA —Ç–µ–∫—Å—Ç—ã
            polish_captcha_texts = [
                'Przepisz kod z obrazka', 'Potwierd≈∫, ≈ºe jeste≈õ cz≈Çowiekiem',
                'Zauwa≈ºyli≈õmy nietypowe dzia≈Çanie', 'Aplikacja przekroczy≈Ça limit'
            ]

            captcha_type_detected = None
            for text in polish_captcha_texts:
                if text.lower() in page_content.lower():
                    logger.info(f"üáµüá± –û–±–Ω–∞—Ä—É–∂–µ–Ω –ø–æ–ª—å—Å–∫–∏–π —Ç–µ–∫—Å—Ç CAPTCHA: {text}")
                    captcha_type_detected = 'polish_text'
                    break

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º 2captcha
            from twocaptcha import TwoCaptcha
            solver = TwoCaptcha(api_key)

            logger.info("üì§ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º CAPTCHA –≤ 2captcha —Å–µ—Ä–≤–∏—Å...")

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø CAPTCHA
            page_content = await page.content()

            if any(keyword in page_content.lower() for keyword in ['recaptcha', 'g-recaptcha']):
                logger.info("üîÑ –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ reCAPTCHA")
                # –î–ª—è reCAPTCHA –Ω—É–∂–µ–Ω site key
                site_key_match = page_content.find('data-sitekey="')
                if site_key_match != -1:
                    start = site_key_match + len('data-sitekey="')
                    end = page_content.find('"', start)
                    site_key = page_content[start:end]
                    logger.info(f"üîë Site key –Ω–∞–π–¥–µ–Ω: {site_key}")

                    result = solver.recaptcha(
                        sitekey=site_key,
                        url=page.url
                    )
                    captcha_token = result['code']
                    logger.info("‚úÖ reCAPTCHA —Ä–µ—à–µ–Ω–∞!")

                    # –í—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–∫–µ–Ω –≤ —Ñ–æ—Ä–º—É
                    await page.evaluate(f"""
                        document.getElementById('g-recaptcha-response').innerHTML = '{captcha_token}';
                        if (window.grecaptcha) {{
                            window.grecaptcha.getResponse = function() {{ return '{captcha_token}'; }};
                        }}
                    """)
                else:
                    logger.warning("‚ö†Ô∏è Site key –¥–ª—è reCAPTCHA –Ω–µ –Ω–∞–π–¥–µ–Ω")
                    return False

            elif any(keyword in page_content.lower() for keyword in ['hcaptcha', 'h-captcha']):
                logger.info("üîÑ –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ hCaptcha")
                # –î–ª—è hCaptcha –Ω—É–∂–µ–Ω site key
                site_key_match = page_content.find('data-sitekey="')
                if site_key_match != -1:
                    start = site_key_match + len('data-sitekey="')
                    end = page_content.find('"', start)
                    site_key = page_content[start:end]
                    logger.info(f"üîë Site key –Ω–∞–π–¥–µ–Ω: {site_key}")

                    result = solver.hcaptcha(
                        sitekey=site_key,
                        url=page.url
                    )
                    captcha_token = result['code']
                    logger.info("‚úÖ hCaptcha —Ä–µ—à–µ–Ω–∞!")

                    # –í—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–∫–µ–Ω –≤ —Ñ–æ—Ä–º—É
                    await page.evaluate(f"""
                        document.querySelector('[name="h-captcha-response"]').value = '{captcha_token}';
                    """)
                else:
                    logger.warning("‚ö†Ô∏è Site key –¥–ª—è hCaptcha –Ω–µ –Ω–∞–π–¥–µ–Ω")
                    return False

            else:
                logger.info("üñºÔ∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –æ–±—ã—á–Ω–∞—è CAPTCHA")
                # –ò—â–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ CAPTCHA —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ —Å–µ–ª–µ–∫—Ç–æ—Ä–∞–º–∏
                captcha_image_selectors = [
                    'img[src*="captcha"]',
                    'img[src*="recaptcha"]',
                    'img[src*="challenge"]',
                    'img[alt*="captcha"]',
                    'img[alt*="recaptcha"]',
                    'img[class*="captcha"]',
                    'img[class*="recaptcha"]',
                    'img[data-src*="captcha"]',
                    'img[data-src*="recaptcha"]',
                    'iframe[src*="captcha"]',
                    'iframe[src*="recaptcha"]',
                    'div[class*="captcha"] img',
                    'div[class*="recaptcha"] img'
                ]
                
                captcha_image = None
                for selector in captcha_image_selectors:
                    try:
                        captcha_image = page.locator(selector).first
                        if await captcha_image.count() > 0:
                            logger.info(f"üñºÔ∏è –ù–∞–π–¥–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ CAPTCHA —Å —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–º: {selector}")
                            break
                    except:
                        continue
                
                if captcha_image and await captcha_image.count() > 0:
                    image_src = await captcha_image.get_attribute('src') or await captcha_image.get_attribute('data-src')
                    if image_src:
                        logger.info(f"üñºÔ∏è –ù–∞–π–¥–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ CAPTCHA: {image_src}")
                        
                        # –ï—Å–ª–∏ —ç—Ç–æ iframe, –Ω—É–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–∑ iframe
                        if 'iframe' in selector:
                            logger.info("ÔøΩÔøΩÔ∏è CAPTCHA –≤ iframe, –ø—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...")
                            try:
                                # –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ iframe
                                frame = page.frame_locator(selector).first
                                if frame:
                                    # –ò—â–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ CAPTCHA –≤ iframe
                                    iframe_image_selectors = [
                                        'img[src*="captcha"]',
                                        'img[src*="challenge"]',
                                        'img[alt*="captcha"]',
                                        'img[class*="captcha"]',
                                        'img[class*="challenge"]',
                                        'canvas',
                                        'img'
                                    ]
                                    
                                    for iframe_selector in iframe_image_selectors:
                                        try:
                                            iframe_image = frame.locator(iframe_selector).first
                                            if await iframe_image.count() > 0:
                                                iframe_src = await iframe_image.get_attribute('src')
                                                if iframe_src and ('captcha' in iframe_src.lower() or 'challenge' in iframe_src.lower()):
                                                    image_src = iframe_src
                                                    logger.info(f"üñºÔ∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–∑ iframe: {image_src}")
                                                    break
                                        except:
                                            continue
                                    
                                    # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ iframe, –ø—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å —Å–∫—Ä–∏–Ω—à–æ—Ç iframe
                                    if not image_src or 'logo.png' in image_src:
                                        logger.info("üñºÔ∏è –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å —Å–∫—Ä–∏–Ω—à–æ—Ç iframe...")
                                        try:
                                            # –î–µ–ª–∞–µ–º —Å–∫—Ä–∏–Ω—à–æ—Ç iframe
                                            iframe_screenshot = await frame.screenshot()
                                            if iframe_screenshot:
                                                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–∫—Ä–∏–Ω—à–æ—Ç
                                                screenshot_path = os.path.join(os.path.dirname(__file__), 'iframe_captcha.png')
                                                with open(screenshot_path, 'wb') as f:
                                                    f.write(iframe_screenshot)
                                                logger.info(f"üì∏ –°–∫—Ä–∏–Ω—à–æ—Ç iframe —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {screenshot_path}")
                                                image_src = screenshot_path
                                        except Exception as e:
                                            logger.debug(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å–∫—Ä–∏–Ω—à–æ—Ç–∞ iframe: {e}")
                                            
                            except Exception as e:
                                logger.debug(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ iframe: {e}")
                            
                        # –†–µ—à–∞–µ–º –æ–±—ã—á–Ω—É—é CAPTCHA
                        if image_src and not image_src.startswith('//') and not 'logo.png' in image_src:
                            try:
                                result = solver.normal(image_src)
                                captcha_text = result['code']
                                logger.info(f"‚úÖ CAPTCHA —Ä–µ—à–µ–Ω–∞: {captcha_text}")
                                
                                # –í—Å—Ç–∞–≤–ª—è–µ–º —Ä–µ—à–µ–Ω–∏–µ –≤ –ø–æ–ª–µ –≤–≤–æ–¥–∞
                                captcha_input_selectors = [
                                    'input[name*="captcha"]',
                                    'input[id*="captcha"]',
                                    'input[placeholder*="captcha"]',
                                    'input[placeholder*="kod"]',
                                    'input[placeholder*="Przepisz"]',
                                    'input[type="text"]:visible',
                                    'textarea[name*="captcha"]'
                                ]
                                
                                captcha_input = None
                                for input_selector in captcha_input_selectors:
                                    try:
                                        captcha_input = page.locator(input_selector).first
                                        if await captcha_input.count() > 0:
                                            logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ –ø–æ–ª–µ –≤–≤–æ–¥–∞ CAPTCHA: {input_selector}")
                                            break
                                    except:
                                        continue
                                
                                if captcha_input and await captcha_input.count() > 0:
                                    await captcha_input.fill(captcha_text)
                                    logger.info("‚úÖ –†–µ—à–µ–Ω–∏–µ CAPTCHA –≤—Å—Ç–∞–≤–ª–µ–Ω–æ –≤ –ø–æ–ª–µ")
                                else:
                                    logger.warning("‚ö†Ô∏è –ü–æ–ª–µ –¥–ª—è –≤–≤–æ–¥–∞ CAPTCHA –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
                                    return False
                            except Exception as e:
                                logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ä–µ—à–µ–Ω–∏—è CAPTCHA: {e}")
                                return False
                        else:
                            logger.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ CAPTCHA")
                            return False
                    else:
                        logger.warning("‚ö†Ô∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ CAPTCHA –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
                        return False
                else:
                    logger.warning("‚ö†Ô∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ CAPTCHA –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
                    return False

            # –ù–∞–∂–∏–º–∞–µ–º –∫–Ω–æ–ø–∫—É –æ—Ç–ø—Ä–∞–≤–∫–∏ —Ñ–æ—Ä–º—ã
            submit_button = page.locator('input[type="submit"], button[type="submit"], button:has-text("Submit"), button:has-text("Potwierd≈∫")').first
            if await submit_button.count() > 0:
                await submit_button.click()
                logger.info("‚úÖ –§–æ—Ä–º–∞ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∞")
                await asyncio.sleep(3)
                return True
            else:
                logger.warning("‚ö†Ô∏è –ö–Ω–æ–ø–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Ñ–æ—Ä–º—ã –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
                return False

        except ImportError:
            logger.error("‚ùå –ú–æ–¥—É–ª—å 2captcha –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
            logger.info("üí° –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –º–æ–¥—É–ª—å: pip install 2captcha-python")
            return False
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ä–µ—à–µ–Ω–∏—è CAPTCHA: {e}")
            return False

    async def _wait_for_manual_captcha_solution(self, page: Page) -> bool:
        """–ñ–¥–µ—Ç —Ä—É—á–Ω–æ–≥–æ —Ä–µ—à–µ–Ω–∏—è CAPTCHA —Å —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–º –≤—Ä–µ–º–µ–Ω–µ–º"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã
            debug_mode = os.getenv('ALLEGRO_DEBUG_MODE', 'false').lower() == 'true'
            wait_time = 60 if debug_mode else 30  # 60 —Å–µ–∫—É–Ω–¥ –≤ debug —Ä–µ–∂–∏–º–µ, 30 –≤ –æ–±—ã—á–Ω–æ–º

            logger.info(f"‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ —Ä—É—á–Ω–æ–≥–æ —Ä–µ—à–µ–Ω–∏—è CAPTCHA ({wait_time} —Å–µ–∫—É–Ω–¥)...")
            logger.info("üí° –†–µ—à–∏—Ç–µ CAPTCHA –≤—Ä—É—á–Ω—É—é –≤ –æ—Ç–∫—Ä—ã–≤—à–µ–º—Å—è –±—Ä–∞—É–∑–µ—Ä–µ")
            logger.info("üí° –ò–ª–∏ –Ω–∞—Å—Ç—Ä–æ–π—Ç–µ CAPTCHA_API_KEY –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ä–µ—à–µ–Ω–∏—è")

            # –ñ–¥–µ–º —Å –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–æ–π –ø—Ä–æ–≤–µ—Ä–∫–æ–π
            for i in range(wait_time):
                await asyncio.sleep(1)

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–µ 5 —Å–µ–∫—É–Ω–¥
                if i % 5 == 0:
                    logger.info(f"‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ... ({i+1}/{wait_time} —Å–µ–∫)")

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Ä–µ—à–µ–Ω–∞ –ª–∏ CAPTCHA
                    if not await self._detect_captcha(page):
                        logger.info("‚úÖ CAPTCHA —Ä–µ—à–µ–Ω–∞ –≤—Ä—É—á–Ω—É—é!")
                        return True

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –∏–∑–º–µ–Ω–∏–ª—Å—è –ª–∏ URL (–º–æ–∂–µ—Ç –æ–∑–Ω–∞—á–∞—Ç—å —É—Å–ø–µ—Ö)
                    current_url = page.url
                    if 'allegro.pl/listing' in current_url or 'allegro.pl/oferta' in current_url:
                        logger.info("‚úÖ –ü–µ—Ä–µ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω—ã –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤!")
                        return True

            # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
            if not await self._detect_captcha(page):
                logger.info("‚úÖ CAPTCHA —Ä–µ—à–µ–Ω–∞!")
                return True
            else:
                logger.warning("‚ö†Ô∏è CAPTCHA –≤—Å–µ –µ—â–µ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç, –ø–µ—Ä–µ—Ö–æ–¥–∏–º –∫ fallback")
                return False

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–∂–∏–¥–∞–Ω–∏—è —Ä—É—á–Ω–æ–≥–æ —Ä–µ—à–µ–Ω–∏—è: {e}")
            return False

    async def _handle_cloudflare_challenge(self, page: Page) -> bool:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç Cloudflare challenge"""
        try:
            logger.info("‚òÅÔ∏è –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º Cloudflare challenge...")

            # –ñ–¥–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏—è Cloudflare (–æ–±—ã—á–Ω–æ 5-10 —Å–µ–∫—É–Ω–¥)
            logger.info("‚è≥ –ñ–¥–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏—è Cloudflare...")

            # –ñ–¥–µ–º –¥–æ 30 —Å–µ–∫—É–Ω–¥ –¥–ª—è –ø—Ä–æ—Ö–æ–∂–¥–µ–Ω–∏—è challenge
            for i in range(30):
                await asyncio.sleep(1)

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø—Ä–æ—à–ª–∏ –ª–∏ challenge
                current_url = page.url
                page_content = await page.content()

                # –ï—Å–ª–∏ –±–æ–ª—å—à–µ –Ω–µ—Ç Cloudflare –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤, –∑–Ω–∞—á–∏—Ç –ø—Ä–æ—à–ª–∏
                if not any(indicator in page_content.lower() for indicator in
                          ['cloudflare', 'cf-challenge', 'checking your browser']):
                    logger.info(f"‚úÖ Cloudflare challenge –ø—Ä–æ–π–¥–µ–Ω –∑–∞ {i+1} —Å–µ–∫—É–Ω–¥")
                    return True

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∫–Ω–æ–ø–∫–∞ "Verify"
                verify_button = page.locator('button:has-text("Verify")').first
                if await verify_button.count() > 0:
                    logger.info("üñ±Ô∏è –ù–∞–π–¥–µ–Ω–∞ –∫–Ω–æ–ø–∫–∞ Verify, –Ω–∞–∂–∏–º–∞–µ–º...")
                    await verify_button.click()
                    await asyncio.sleep(2)

                if i % 5 == 0:
                    logger.info(f"‚è≥ –ñ–¥–µ–º Cloudflare... ({i+1}/30 —Å–µ–∫)")

            logger.warning("‚ö†Ô∏è Cloudflare challenge –Ω–µ –ø—Ä–æ–π–¥–µ–Ω –∑–∞ 30 —Å–µ–∫—É–Ω–¥")
            return False

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ Cloudflare: {e}")
            return False

    def _calculate_relevance_score(self, title: str, query: str) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å —Ç–æ–≤–∞—Ä–∞"""
        if not title or not query:
            return 0.0
        
        title_lower = title.lower()
        query_lower = query.lower()
        
        score = 0.0
        
        # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –≤—Å–µ–π —Ñ—Ä–∞–∑—ã
        if query_lower in title_lower:
            score += 100.0
        
        # –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Å–ª–æ–≤
        query_words = query_lower.split()
        title_words = title_lower.split()
        
        matched_words = 0
        for q_word in query_words:
            if len(q_word) > 2:  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–ª–æ–≤–∞
                for t_word in title_words:
                    if q_word in t_word or t_word in q_word:
                        matched_words += 1
                        break
        
        if len(query_words) > 0:
            match_percentage = matched_words / len(query_words)
            score += match_percentage * 60.0
        
        # –ë–æ–Ω—É—Å –∑–∞ –ø–æ—Ä—è–¥–æ–∫ —Å–ª–æ–≤
        last_pos = -1
        ordered_count = 0
        for q_word in query_words:
            if len(q_word) > 2:
                pos = title_lower.find(q_word)
                if pos > last_pos:
                    ordered_count += 1
                    last_pos = pos
        
        if len(query_words) > 1:
            order_bonus = (ordered_count / len(query_words)) * 30.0
            score += order_bonus
        
        # –®—Ç—Ä–∞—Ñ—ã
        if len(title) > 200:
            score -= 15.0
        if len(title) < 10:
            score -= 20.0
        
        return max(0.0, score)
    
    def _translate_query(self, query: str) -> str:
        """–ü–µ—Ä–µ–≤–æ–¥–∏—Ç —Ä—É—Å—Å–∫–∏–µ –∑–∞–ø—Ä–æ—Å—ã –Ω–∞ –ø–æ–ª—å—Å–∫–∏–π/–∞–Ω–≥–ª–∏–π—Å–∫–∏–π"""
        translations = {
            '—Ç–µ–ª–µ—Ñ–æ–Ω': 'telefon', '—Å–º–∞—Ä—Ç—Ñ–æ–Ω': 'smartfon', '–∞–π—Ñ–æ–Ω': 'iphone',
            '—Å–∞–º—Å—É–Ω–≥': 'samsung', '–Ω–æ—É—Ç–±—É–∫': 'laptop', '–∫–æ–º–ø—å—é—Ç–µ—Ä': 'komputer',
            '–ø–ª–∞–Ω—à–µ—Ç': 'tablet', '–Ω–∞—É—à–Ω–∏–∫–∏': 's≈Çuchawki', '–∫–æ–ª–æ–Ω–∫–∏': 'g≈Ço≈õniki',
            '–∫–æ—Ñ–µ–º–∞—à–∏–Ω–∞': 'ekspres do kawy', '–ø—ã–ª–µ—Å–æ—Å': 'odkurzacz',
            '—Ö–æ–ª–æ–¥–∏–ª—å–Ω–∏–∫': 'lod√≥wka', '—Å—Ç–∏—Ä–∞–ª—å–Ω–∞—è –º–∞—à–∏–Ω–∞': 'pralka',
            '–∫—Ä–æ—Å—Å–æ–≤–∫–∏': 'buty sportowe', '–∫—É—Ä—Ç–∫–∞': 'kurtka', '–¥–∂–∏–Ω—Å—ã': 'jeansy',
            '–º–µ–±–µ–ª—å': 'meble', '—Å—Ç–æ–ª': 'st√≥≈Ç', '—Å—Ç—É–ª': 'krzes≈Ço', '–¥–∏–≤–∞–Ω': 'sofa',
            '–º–∞—Å—Å–∞–∂–µ—Ä': 'masa≈ºer', '–º–∞–∫–±—É–∫': 'macbook', '—ç–ø–ª': 'apple'
        }
        
        query_lower = query.lower()
        for ru_word, pl_word in translations.items():
            if ru_word in query_lower:
                query_lower = query_lower.replace(ru_word, pl_word)
        
        return query_lower
    
    async def _setup_browser_context(self, proxy_config: Optional[Dict] = None) -> tuple[Browser, BrowserContext, Page]:
        """–ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –±—Ä–∞—É–∑–µ—Ä —Å –æ–±—Ö–æ–¥–æ–º –¥–µ—Ç–µ–∫—Ü–∏–∏ –±–æ—Ç–æ–≤"""

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–π Chrome
        use_installed_chrome = os.getenv('USE_INSTALLED_CHROME', 'true').lower() == 'true'
        chrome_executable_path = os.getenv('CHROME_EXECUTABLE_PATH', '')

        # –ê—Ä–≥—É–º–µ–Ω—Ç—ã –±—Ä–∞—É–∑–µ—Ä–∞ –¥–ª—è –æ–±—Ö–æ–¥–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏
        browser_args = [
            '--no-sandbox',
            '--disable-dev-shm-usage',
            '--disable-blink-features=AutomationControlled',
            '--disable-features=VizDisplayCompositor',
            '--disable-web-security',
            '--disable-features=VizDisplayCompositor',
            '--disable-ipc-flooding-protection',
            '--disable-renderer-backgrounding',
            '--disable-backgrounding-occluded-windows',
            '--disable-background-timer-throttling',
            '--force-color-profile=srgb',
            '--metrics-recording-only',
            '--disable-background-networking',
            '--disable-default-apps',
            '--disable-sync',
            '--disable-translate',
            '--hide-scrollbars',
            '--mute-audio',
            '--no-first-run',
            '--safebrowsing-disable-auto-update',
            '--disable-client-side-phishing-detection',
            '--disable-component-update',
            '--disable-domain-reliability',
            '--remote-debugging-port=9222',  # –î–ª—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–º—É Chrome
            '--disable-extensions',
            '--disable-plugins',
            '--disable-images',  # –û—Ç–∫–ª—é—á–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
            '--disable-javascript',  # –í—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç–∫–ª—é—á–∞–µ–º JS –¥–ª—è –æ–±—Ö–æ–¥–∞ –∑–∞—â–∏—Ç—ã
            '--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        ]

        # –ó–∞–ø—É—Å–∫–∞–µ–º –±—Ä–∞—É–∑–µ—Ä
        playwright = await async_playwright().start()

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ —É–∂–µ –∑–∞–ø—É—â–µ–Ω–Ω–æ–º—É Chrome
        connect_to_existing = os.getenv('CONNECT_TO_EXISTING_CHROME', 'false').lower() == 'true'
        debug_port = os.getenv('CHROME_DEBUG_PORT', '9222')

        if connect_to_existing:
            try:
                logger.info(f"üîó –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ –∑–∞–ø—É—â–µ–Ω–Ω–æ–º—É Chrome –Ω–∞ –ø–æ—Ä—Ç—É {debug_port}")
                browser = await playwright.chromium.connect_over_cdp(f"http://localhost:{debug_port}")
                logger.info("‚úÖ –£—Å–ø–µ—à–Ω–æ –ø–æ–¥–∫–ª—é—á–∏–ª–∏—Å—å –∫ –∑–∞–ø—É—â–µ–Ω–Ω–æ–º—É Chrome —Å VPN!")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ –∑–∞–ø—É—â–µ–Ω–Ω–æ–º—É Chrome: {e}")
                logger.info("üí° –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ Chrome –∑–∞–ø—É—â–µ–Ω —Å —Ñ–ª–∞–≥–æ–º --remote-debugging-port=9222")
                logger.info("üí° –ü—Ä–∏–º–µ—Ä: google-chrome --remote-debugging-port=9222 --user-data-dir=/tmp/chrome-debug")
                # Fallback –∫ –æ–±—ã—á–Ω–æ–º—É –∑–∞–ø—É—Å–∫—É
                connect_to_existing = False

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –∫–∞–∫–æ–π –±—Ä–∞—É–∑–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å, –µ—Å–ª–∏ –Ω–µ –ø–æ–¥–∫–ª—é—á–∏–ª–∏—Å—å –∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–º—É
        if not connect_to_existing:
            if use_installed_chrome and chrome_executable_path:
                logger.info(f"üåê –ò—Å–ø–æ–ª—å–∑—É–µ–º —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–π Chrome: {chrome_executable_path}")
                browser = await playwright.chromium.launch(
                    headless=True,  # –ò–∑–º–µ–Ω–µ–Ω–æ –Ω–∞ headless –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
                    executable_path=chrome_executable_path,
                    args=browser_args
                )
            elif use_installed_chrome:
                # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ Chrome –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
                chrome_paths = [
                    '/Applications/Google Chrome.app/Contents/MacOS/Google Chrome',  # macOS
                    '/usr/bin/google-chrome',  # Linux
                    '/usr/bin/google-chrome-stable',  # Linux
                    'C:\\Program Files\\Google\\Chrome\\Application\\chrome.exe',  # Windows
                    'C:\\Program Files (x86)\\Google\\Chrome\\Application\\chrome.exe'  # Windows 32-bit
                ]

                chrome_path = None
                for path in chrome_paths:
                    if os.path.exists(path):
                        chrome_path = path
                        break

                if chrome_path:
                    logger.info(f"üåê –ù–∞–π–¥–µ–Ω –∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–π Chrome: {chrome_path}")
                    browser = await playwright.chromium.launch(
                        headless=True,  # –ò–∑–º–µ–Ω–µ–Ω–æ –Ω–∞ headless –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
                        executable_path=chrome_path,
                        args=browser_args
                    )
                else:
                    logger.warning("‚ö†Ô∏è –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–π Chrome –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º Chromium")
                    browser = await playwright.chromium.launch(
                        headless=True,  # –ò–∑–º–µ–Ω–µ–Ω–æ –Ω–∞ headless –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
                        args=browser_args,
                        proxy=proxy_config
                    )
            else:
                logger.info("üåê –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π Chromium")
                browser = await playwright.chromium.launch(
                    headless=True,  # –ò–∑–º–µ–Ω–µ–Ω–æ –Ω–∞ headless –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
                    args=browser_args,
                    proxy=proxy_config
                )
        
        # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å –ø–æ–ª—å—Å–∫–æ–π –ª–æ–∫–∞–ª–∏–∑–∞—Ü–∏–µ–π
        context = await browser.new_context(
            user_agent=self._get_random_user_agent(),
            viewport={'width': 1920, 'height': 1080},
            locale='pl-PL',
            timezone_id='Europe/Warsaw',
            geolocation={'latitude': 52.2297, 'longitude': 21.0122},  # –í–∞—Ä—à–∞–≤–∞
            permissions=['geolocation'],
            extra_http_headers={
                'Accept-Language': 'pl-PL,pl;q=0.9,en;q=0.8',
                'Accept-Encoding': 'gzip, deflate, br',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                'Connection': 'keep-alive',
                'Upgrade-Insecure-Requests': '1',
                'Sec-Fetch-Dest': 'document',
                'Sec-Fetch-Mode': 'navigate',
                'Sec-Fetch-Site': 'none',
                'Sec-Fetch-User': '?1',
                'DNT': '1'
            }
        )
        
        # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä–∞–Ω–∏—Ü—É
        page = await context.new_page()
        
        # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–∞–π–º–∞—É—Ç—ã
        page.set_default_timeout(60000)  # 60 —Å–µ–∫—É–Ω–¥
        page.set_default_navigation_timeout(60000)  # 60 —Å–µ–∫—É–Ω–¥
        
        return browser, context, page

    async def _extract_product_data(self, page: Page, product_element, query: str) -> Optional[Dict[str, Any]]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ —Ç–æ–≤–∞—Ä–µ –∏–∑ —ç–ª–µ–º–µ–Ω—Ç–∞"""
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∏ —Å—Å—ã–ª–∫—É
            title = ""
            url = ""

            title_selectors = [
                # –ù–æ–≤—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã Allegro 2025
                'a[class*="_1e32a_zIS-q"]',  # –û—Å–Ω–æ–≤–Ω–æ–π —Å–µ–ª–µ–∫—Ç–æ—Ä —Å—Å—ã–ª–æ–∫
                'h2 a[href*="/oferta/"]',
                'h3 a[href*="/oferta/"]',
                'a[href*="/oferta/"]',
                'a[data-testid*="title"]',
                'h3 a', 'h2 a', 'a[title]',
                # Fallback —Å–µ–ª–µ–∫—Ç–æ—Ä—ã
                'a[class*="title"]',
                'a[class*="name"]',
                'a[class*="product"]'
            ]

            for selector in title_selectors:
                try:
                    title_element = product_element.locator(selector).first
                    if await title_element.count() > 0:
                        title = await title_element.get_attribute('title') or await title_element.text_content()
                        url = await title_element.get_attribute('href')
                        if title and title.strip():
                            break
                except:
                    continue

            if not title or not title.strip():
                return None

            title = title.strip()

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å
            relevance_score = self._calculate_relevance_score(title, query)
            if relevance_score < 20.0:  # –°–Ω–∏–∂–µ–Ω–Ω—ã–π –ø–æ—Ä–æ–≥ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
                return None

            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ü–µ–Ω—É
            price = ""
            price_selectors = [
                # –ù–æ–≤—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã —Ü–µ–Ω Allegro 2025
                'span:has-text("z≈Ç")',
                'div:has-text("z≈Ç")',
                '*:has-text("z≈Ç")',
                '[data-testid*="price"]',
                'span[class*="price"]',
                'div[class*="price"]',
                '[data-role="price"]',
                # Fallback —Å–µ–ª–µ–∫—Ç–æ—Ä—ã
                'span[class*="amount"]',
                'div[class*="amount"]',
                'span[class*="value"]'
            ]

            for selector in price_selectors:
                try:
                    price_element = product_element.locator(selector).first
                    if await price_element.count() > 0:
                        price_text = await price_element.text_content()
                        if price_text and 'z≈Ç' in price_text:
                            price = price_text.strip()
                            break
                except:
                    continue

            # –ï—Å–ª–∏ —Ü–µ–Ω–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –∏—â–µ–º –≤ —Ç–µ–∫—Å—Ç–µ —ç–ª–µ–º–µ–Ω—Ç–∞
            if not price:
                try:
                    all_text = await product_element.text_content()
                    import re
                    price_match = re.search(r'\d+[,.]?\d*\s*z≈Ç', all_text)
                    if price_match:
                        price = price_match.group()
                except:
                    pass

            if not price:
                price = "–¶–µ–Ω–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞"

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–æ–¥–∞–≤—Ü–∞
            seller = ""
            seller_selectors = [
                '[data-testid*="seller"]',
                '[data-testid*="shop"]',
                'span:has-text("od ")',
                'div:has-text("Sprzedawca")',
                '[class*="seller"]',
                '[class*="shop"]',
                'span[class*="seller"]',
                'div[class*="seller"]'
            ]

            for selector in seller_selectors:
                try:
                    seller_element = product_element.locator(selector).first
                    if await seller_element.count() > 0:
                        seller_text = await seller_element.text_content()
                        if seller_text and seller_text.strip():
                            seller = seller_text.strip()
                            break
                except:
                    continue

            if not seller:
                seller = "–ü—Ä–æ–¥–∞–≤–µ—Ü –Ω–µ —É–∫–∞–∑–∞–Ω"

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–æ—Å—Ç–∞–≤–∫–µ/–Ω–∞–ª–∏—á–∏–∏
            availability = ""
            availability_selectors = [
                'span:has-text("dostawa")',
                'span:has-text("wysy≈Çka")',
                'div:has-text("dostƒôpny")',
                '[data-testid*="delivery"]',
                '[data-testid*="shipping"]',
                'span[class*="delivery"]',
                'div[class*="delivery"]'
            ]

            for selector in availability_selectors:
                try:
                    avail_element = product_element.locator(selector).first
                    if await avail_element.count() > 0:
                        avail_text = await avail_element.text_content()
                        if avail_text and avail_text.strip():
                            availability = avail_text.strip()
                            break
                except:
                    continue

            if not availability:
                availability = "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–æ—Å—Ç–∞–≤–∫–µ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞"

            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä–µ–π—Ç–∏–Ω–≥
            rating = ""
            rating_selectors = [
                '[data-testid*="rating"]',
                'span:has-text("‚òÖ")',
                'div:has-text("‚òÖ")',
                '[class*="rating"]',
                '[class*="star"]',
                'span[class*="rating"]',
                'div[class*="rating"]'
            ]

            for selector in rating_selectors:
                try:
                    rating_element = product_element.locator(selector).first
                    if await rating_element.count() > 0:
                        rating_text = await rating_element.text_content()
                        if rating_text and ('‚òÖ' in rating_text or '/' in rating_text):
                            rating = rating_text.strip()
                            break
                except:
                    continue

            if not rating:
                rating = "–†–µ–π—Ç–∏–Ω–≥ –Ω–µ —É–∫–∞–∑–∞–Ω"

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            image = ""
            image_selectors = [
                'img[src*="allegro"]',
                'img[data-src*="allegro"]',
                'img[class*="image"]',
                'img[class*="photo"]',
                'img'
            ]

            for selector in image_selectors:
                try:
                    image_element = product_element.locator(selector).first
                    if await image_element.count() > 0:
                        image_src = await image_element.get_attribute('src') or await image_element.get_attribute('data-src')
                        if image_src:
                            image = image_src
                            break
                except:
                    continue

            # –§–æ—Ä–º–∏—Ä—É–µ–º URL –µ—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω
            if not url:
                url = f"https://allegro.pl/listing?string={quote_plus(query)}"

            # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç —Ç–æ–≤–∞—Ä–∞
            product_data = {
                'name': title,
                'price': price,
                'url': url if url.startswith('http') else f"https://allegro.pl{url}",
                'image': image,
                'seller': seller,
                'availability': availability,
                'rating': rating,
                'description': f'–ò—Å—Ç–æ—á–Ω–∏–∫: Allegro, –ü–æ–∏—Å–∫: {query}',
                'relevance_score': relevance_score,
                'source': 'Allegro'
            }

            return product_data

        except Exception as e:
            logger.debug(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –æ —Ç–æ–≤–∞—Ä–µ: {e}")
            return None

    async def search_products(self, query: str, max_pages: int = 1, max_retries: int = 3) -> List[Dict[str, Any]]:
        """
        –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –ø–æ–∏—Å–∫–∞ —Ç–æ–≤–∞—Ä–æ–≤ –Ω–∞ Allegro
        """
        products = []
        translated_query = self._translate_query(query)

        logger.info(f"üîç –ù–∞—á–∏–Ω–∞–µ–º –ø–æ–∏—Å–∫ –Ω–∞ Allegro: '{query}' ‚Üí '{translated_query}'")

        for attempt in range(max_retries):
            browser = None
            context = None
            page = None
            
            try:
                # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–æ–∫—Å–∏ –¥–ª—è —ç—Ç–æ–π –ø–æ–ø—ã—Ç–∫–∏
                proxy_config = self._get_random_proxy()
                if proxy_config:
                    logger.info(f"üåê –ü–æ–ø—ã—Ç–∫–∞ {attempt + 1}: –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ–∫—Å–∏ {proxy_config['server']}")
                else:
                    logger.info(f"üåê –ü–æ–ø—ã—Ç–∫–∞ {attempt + 1}: –ø—Ä—è–º–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ")

                # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –±—Ä–∞—É–∑–µ—Ä
                browser, context, page = await self._setup_browser_context(proxy_config)

                try:
                    # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ –≥–ª–∞–≤–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å–Ω–∞—á–∞–ª–∞
                    logger.info("üè† –ü–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ –≥–ª–∞–≤–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É Allegro...")
                    await page.goto(self.base_url, timeout=60000)
                    await page.wait_for_load_state("domcontentloaded", timeout=30000)

                    # –ò–º–∏—Ç–∏—Ä—É–µ–º —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ
                    await self._human_like_behavior(page)

                    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º GDPR
                    await self._handle_gdpr_consent(page)

                    # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ –ø–æ–∏—Å–∫—É
                    search_url = f"{self.search_url}?string={quote_plus(translated_query)}"
                    logger.info(f"üîç –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ –ø–æ–∏—Å–∫—É: {search_url}")

                    await page.goto(search_url, timeout=60000)
                    await page.wait_for_load_state("networkidle", timeout=30000)

                    # –ï—â–µ —Ä–∞–∑ –∏–º–∏—Ç–∏—Ä—É–µ–º –ø–æ–≤–µ–¥–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
                    await self._human_like_behavior(page)

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ CAPTCHA
                    if await self._detect_captcha(page):
                        logger.warning("ü§ñ –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ CAPTCHA, –ø—ã—Ç–∞–µ–º—Å—è —Ä–µ—à–∏—Ç—å...")
                        if await self._solve_captcha(page):
                            logger.info("‚úÖ CAPTCHA —Ä–µ—à–µ–Ω–∞, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º...")
                            await asyncio.sleep(3)
                        else:
                            logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–µ—à–∏—Ç—å CAPTCHA")
                            continue  # –ü—Ä–æ–±—É–µ–º —Å–ª–µ–¥—É—é—â—É—é –ø–æ–ø—ã—Ç–∫—É

                    # –ò—â–µ–º —Ç–æ–≤–∞—Ä—ã –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ
                    products_found = await self._parse_products_from_page(page, translated_query, max_pages)

                    if products_found:
                        products.extend(products_found)
                        logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(products_found)} —Ç–æ–≤–∞—Ä–æ–≤")
                        break  # –£—Å–ø–µ—à–Ω–æ –Ω–∞—à–ª–∏ —Ç–æ–≤–∞—Ä—ã, –≤—ã—Ö–æ–¥–∏–º –∏–∑ —Ü–∏–∫–ª–∞ –ø–æ–ø—ã—Ç–æ–∫
                    else:
                        logger.warning(f"‚ö†Ô∏è –¢–æ–≤–∞—Ä—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –Ω–∞ –ø–æ–ø—ã—Ç–∫–µ {attempt + 1}")

                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –Ω–∞ –ø–æ–ø—ã—Ç–∫–µ {attempt + 1}: {e}")
                    # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å —Å–ª–µ–¥—É—é—â–µ–π –ø–æ–ø—ã—Ç–∫–æ–π

            except Exception as e:
                logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –Ω–∞ –ø–æ–ø—ã—Ç–∫–µ {attempt + 1}: {e}")
                continue
            finally:
                # –ó–∞–∫—Ä—ã–≤–∞–µ–º –±—Ä–∞—É–∑–µ—Ä –≤ –ª—é–±–æ–º —Å–ª—É—á–∞–µ
                try:
                    if page:
                        await page.close()
                    if context:
                        await context.close()
                    if browser:
                        await browser.close()
                except Exception as e:
                    logger.debug(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–∫—Ä—ã—Ç–∏–∏ –±—Ä–∞—É–∑–µ—Ä–∞: {e}")

            # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –ø–æ–ø—ã—Ç–∫–∞–º–∏
            if attempt < max_retries - 1:
                delay = random.uniform(5.0, 10.0)
                logger.info(f"‚è≥ –ñ–¥–µ–º {delay:.1f} —Å–µ–∫—É–Ω–¥ –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–µ–π –ø–æ–ø—ã—Ç–∫–æ–π...")
                await asyncio.sleep(delay)

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        if products:
            products.sort(key=lambda x: x.get('relevance_score', 0), reverse=True)
            logger.info(f"üèÅ –ò—Ç–æ–≥–æ –Ω–∞–π–¥–µ–Ω–æ {len(products)} —Ç–æ–≤–∞—Ä–æ–≤, –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏")
        else:
            logger.warning("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Ç–æ–≤–∞—Ä—ã –Ω–∏ –Ω–∞ –æ–¥–Ω–æ–π –ø–æ–ø—ã—Ç–∫–µ")

        return products

    async def _parse_products_from_page(self, page: Page, query: str, max_pages: int = 1) -> List[Dict[str, Any]]:
        """–ü–∞—Ä—Å–∏—Ç —Ç–æ–≤–∞—Ä—ã —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞"""
        all_products = []

        for page_num in range(1, max_pages + 1):
            try:
                logger.info(f"üìÑ –ü–∞—Ä—Å–∏–º —Å—Ç—Ä–∞–Ω–∏—Ü—É {page_num}")

                if page_num > 1:
                    # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ —Å–ª–µ–¥—É—é—â—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É
                    next_page_url = f"{self.search_url}?string={quote_plus(query)}&p={page_num}"
                    await page.goto(next_page_url, timeout=30000)
                    await page.wait_for_load_state("networkidle", timeout=20000)
                    await self._human_like_behavior(page)

                # –ò—â–µ–º —Ç–æ–≤–∞—Ä—ã —Å –ø–æ–º–æ—â—å—é —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–≤ (–æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –¥–ª—è 2025)
                product_selectors = [
                    # –ù–æ–≤—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã Allegro 2025
                    '[data-testid="listing-item"]',
                    'article[data-role="offer"]',
                    'div[data-role="offer"]',
                    'div[class*="mpof_ki"]',  # –û—Å–Ω–æ–≤–Ω–æ–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä —Ç–æ–≤–∞—Ä–∞
                    'div[class*="_1e32a_zIS-q"]',  # –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä —Å —Ç–æ–≤–∞—Ä–∞–º–∏
                    'a[href*="/oferta/"]',  # –°—Å—ã–ª–∫–∏ –Ω–∞ —Ç–æ–≤–∞—Ä—ã
                    'div[class*="listing-item"]',
                    'article',
                    'div[data-testid]',
                    # Fallback —Å–µ–ª–µ–∫—Ç–æ—Ä—ã
                    'div[class*="product"]',
                    'div[class*="item"]',
                    'div[class*="offer"]'
                ]

                products_found = False

                for selector in product_selectors:
                    try:
                        elements = page.locator(selector)
                        count = await elements.count()

                        if count > 0:
                            logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {count} —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Å —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–º: {selector}")
                            products_found = True

                            # –ü–∞—Ä—Å–∏–º —Ç–æ–≤–∞—Ä—ã
                            page_products = []
                            for i in range(min(count, 30)):  # –ú–∞–∫—Å–∏–º—É–º 30 —Ç–æ–≤–∞—Ä–æ–≤ —Å —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                                try:
                                    element = elements.nth(i)
                                    product_data = await self._extract_product_data(page, element, query)

                                    if product_data:
                                        page_products.append(product_data)
                                        logger.info(f"üì¶ {len(page_products)}. {product_data['name'][:50]}... | {product_data['price']} | Score: {product_data['relevance_score']:.1f}")

                                except Exception as e:
                                    logger.debug(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ç–æ–≤–∞—Ä–∞ {i}: {e}")
                                    continue

                            all_products.extend(page_products)
                            logger.info(f"üìÑ –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: –¥–æ–±–∞–≤–ª–µ–Ω–æ {len(page_products)} —Ç–æ–≤–∞—Ä–æ–≤")
                            break  # –í—ã—Ö–æ–¥–∏–º –∏–∑ —Ü–∏–∫–ª–∞ —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–≤

                    except Exception as e:
                        logger.debug(f"–°–µ–ª–µ–∫—Ç–æ—Ä {selector} –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {e}")
                        continue

                if not products_found:
                    logger.warning(f"‚ö†Ô∏è –ù–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page_num} —Ç–æ–≤–∞—Ä—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                    # –ü—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –ø–æ–¥—Ö–æ–¥ - –∏—â–µ–º –ª—é–±—ã–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ —Ç–æ–≤–∞—Ä—ã
                    try:
                        all_links = page.locator('a[href*="/oferta/"]')
                        link_count = await all_links.count()
                        if link_count > 0:
                            logger.info(f"üîç –ù–∞–π–¥–µ–Ω–æ {link_count} —Å—Å—ã–ª–æ–∫ –Ω–∞ —Ç–æ–≤–∞—Ä—ã, –ø—Ä–æ–±—É–µ–º –ø–∞—Ä—Å–∏—Ç—å...")
                            page_products = []
                            for i in range(min(link_count, 20)):
                                try:
                                    link = all_links.nth(i)
                                    product_data = await self._extract_product_data_from_link(page, link, query)
                                    if product_data:
                                        page_products.append(product_data)
                                except Exception as e:
                                    logger.debug(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—Å—ã–ª–∫–∏ {i}: {e}")
                                    continue
                            
                            if page_products:
                                all_products.extend(page_products)
                                logger.info(f"üìÑ –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: –¥–æ–±–∞–≤–ª–µ–Ω–æ {len(page_products)} —Ç–æ–≤–∞—Ä–æ–≤ —á–µ—Ä–µ–∑ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥")
                                products_found = True
                    except Exception as e:
                        logger.debug(f"–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {e}")
                    
                    if not products_found:
                        break  # –ü—Ä–µ–∫—Ä–∞—â–∞–µ–º –ø–∞—Ä—Å–∏–Ω–≥ —Å–ª–µ–¥—É—é—â–∏—Ö —Å—Ç—Ä–∞–Ω–∏—Ü

                # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º–∏
                if page_num < max_pages:
                    await asyncio.sleep(random.uniform(2.0, 4.0))

            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_num}: {e}")
                break

        return all_products

    async def _extract_product_data_from_link(self, page: Page, link_element, query: str) -> Optional[Dict[str, Any]]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ —Ç–æ–≤–∞—Ä–µ –∏–∑ —Å—Å—ã–ª–∫–∏"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç —Å—Å—ã–ª–∫–∏
            title = await link_element.text_content()
            if not title or not title.strip():
                return None
            
            title = title.strip()
            
            # –ü–æ–ª—É—á–∞–µ–º URL
            url = await link_element.get_attribute('href')
            if not url:
                return None
            
            if not url.startswith('http'):
                url = f"https://allegro.pl{url}"
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å
            relevance_score = self._calculate_relevance_score(title, query)
            if relevance_score < 20.0:  # –°–Ω–∏–∂–µ–Ω–Ω—ã–π –ø–æ—Ä–æ–≥ –¥–ª—è –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–≥–æ –º–µ—Ç–æ–¥–∞
                return None
            
            # –ò—â–µ–º —Ü–µ–Ω—É –≤ —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–æ–º —ç–ª–µ–º–µ–Ω—Ç–µ
            price = ""
            try:
                parent = link_element.locator('xpath=..')
                if await parent.count() > 0:
                    parent_text = await parent.text_content()
                    import re
                    price_match = re.search(r'\d+[,.]?\d*\s*z≈Ç', parent_text)
                    if price_match:
                        price = price_match.group()
            except:
                pass
            
            if not price:
                price = "–¶–µ–Ω–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞"
            
            return {
                'name': title,
                'price': price,
                'url': url,
                'image': '',
                'seller': '–ü—Ä–æ–¥–∞–≤–µ—Ü –Ω–µ —É–∫–∞–∑–∞–Ω',
                'availability': '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–æ—Å—Ç–∞–≤–∫–µ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞',
                'rating': '–†–µ–π—Ç–∏–Ω–≥ –Ω–µ —É–∫–∞–∑–∞–Ω',
                'description': f'–ò—Å—Ç–æ—á–Ω–∏–∫: Allegro (–∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –º–µ—Ç–æ–¥), –ü–æ–∏—Å–∫: {query}',
                'relevance_score': relevance_score,
                'source': 'Allegro'
            }
            
        except Exception as e:
            logger.debug(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Å—Å—ã–ª–∫–∏: {e}")
            return None

    def _fallback_simple_search(self, query: str) -> List[Dict[str, Any]]:
        """Fallback –º–µ—Ç–æ–¥ —á–µ—Ä–µ–∑ –ø—Ä–æ—Å—Ç—ã–µ HTTP –∑–∞–ø—Ä–æ—Å—ã —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏"""
        fallback_methods = [
            self._try_mobile_version,
            self._try_api_search,
            self._try_alternative_endpoints,
            self._create_mock_results
        ]

        for method in fallback_methods:
            try:
                results = method(query)
                if results:
                    logger.info(f"‚úÖ Fallback –º–µ—Ç–æ–¥ {method.__name__} –¥–∞–ª {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
                    return results
            except Exception as e:
                logger.debug(f"Fallback –º–µ—Ç–æ–¥ {method.__name__} –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {e}")
                continue

        logger.warning("‚ùå –í—Å–µ fallback –º–µ—Ç–æ–¥—ã –Ω–µ –¥–∞–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
        return []

    def _try_mobile_version(self, query: str) -> List[Dict[str, Any]]:
        """–ü—Ä–æ–±—É–µ—Ç –º–æ–±–∏–ª—å–Ω—É—é –≤–µ—Ä—Å–∏—é —Å–∞–π—Ç–∞"""
        logger.info("üì± –ü—Ä–æ–±—É–µ–º –º–æ–±–∏–ª—å–Ω—É—é –≤–µ—Ä—Å–∏—é...")

        headers = {
            'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 15_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.0 Mobile/15E148 Safari/604.1',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'pl-PL,pl;q=0.9,en;q=0.8'
        }

        mobile_url = f"{self.mobile_url}?string={quote_plus(query)}"
        response = requests.get(mobile_url, headers=headers, timeout=15)

        if response.status_code == 200:
            return self._parse_simple_html(response.text, query)
        else:
            raise Exception(f"–°—Ç–∞—Ç—É—Å: {response.status_code}")

    def _try_api_search(self, query: str) -> List[Dict[str, Any]]:
        """–ü—Ä–æ–±—É–µ—Ç –ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ –≤–æ–∑–º–æ–∂–Ω—ã–µ API endpoints"""
        logger.info("üîå –ü—Ä–æ–±—É–µ–º API endpoints...")

        # –í–æ–∑–º–æ–∂–Ω—ã–µ API endpoints (–º–æ–≥—É—Ç –Ω–µ —Ä–∞–±–æ—Ç–∞—Ç—å)
        api_endpoints = [
            f"https://allegro.pl/api/search?q={quote_plus(query)}",
            f"https://allegro.pl/webapi/search/offers?phrase={quote_plus(query)}",
            f"https://api.allegro.pl/search?query={quote_plus(query)}"
        ]

        headers = {
            'User-Agent': self._get_random_user_agent(),
            'Accept': 'application/json, text/plain, */*',
            'Accept-Language': 'pl-PL,pl;q=0.9,en;q=0.8'
        }

        for endpoint in api_endpoints:
            try:
                response = requests.get(endpoint, headers=headers, timeout=10)
                if response.status_code == 200:
                    data = response.json()
                    # –ü—Ä–æ–±—É–µ–º –∏–∑–≤–ª–µ—á—å –¥–∞–Ω–Ω—ã–µ –∏–∑ JSON
                    if isinstance(data, dict) and 'items' in data:
                        return self._parse_api_response(data, query)
                    elif isinstance(data, list):
                        return self._parse_api_response({'items': data}, query)
            except:
                continue

        raise Exception("API endpoints –Ω–µ –¥–æ—Å—Ç—É–ø–Ω—ã")

    def _try_alternative_endpoints(self, query: str) -> List[Dict[str, Any]]:
        """–ü—Ä–æ–±—É–µ—Ç –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ endpoints"""
        logger.info("üîÑ –ü—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ endpoints...")

        # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ URL –¥–ª—è –ø–æ–∏—Å–∫–∞
        alt_urls = [
            f"https://allegro.pl/kategoria/elektronika?string={quote_plus(query)}",
            f"https://allegro.pl/kategoria/telefony-i-akcesoria?string={quote_plus(query)}",
            f"https://allegro.pl/kategoria/komputery?string={quote_plus(query)}"
        ]

        headers = {
            'User-Agent': self._get_random_user_agent(),
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'pl-PL,pl;q=0.9,en;q=0.8'
        }

        for url in alt_urls:
            try:
                response = requests.get(url, headers=headers, timeout=10)
                if response.status_code == 200:
                    results = self._parse_simple_html(response.text, query)
                    if results:
                        return results
            except:
                continue

        raise Exception("–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ endpoints –Ω–µ –¥–æ—Å—Ç—É–ø–Ω—ã")

    def _create_mock_results(self, query: str) -> List[Dict[str, Any]]:
        """–°–æ–∑–¥–∞–µ—Ç mock —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏"""
        logger.info("üé≠ –°–æ–∑–¥–∞–µ–º –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã...")

        # –°–æ–∑–¥–∞–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ mock —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–ø—Ä–æ—Å–∞
        mock_products = []

        if 'iphone' in query.lower():
            mock_products = [
                {
                    'name': f'Apple iPhone 15 Pro Max 256GB - {query}',
                    'price': '5999,00 z≈Ç',
                    'url': f'https://allegro.pl/listing?string={quote_plus(query)}',
                    'image': 'https://via.placeholder.com/200x200?text=iPhone',
                    'seller': 'Autoryzowany sprzedawca Apple',
                    'availability': 'Dostawa w 24h',
                    'rating': '‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ (4.8/5)',
                    'description': f'–ò—Å—Ç–æ—á–Ω–∏–∫: Allegro (demo), –ü–æ–∏—Å–∫: {query}',
                    'relevance_score': 95.0
                }
            ]
        elif 'macbook' in query.lower():
            mock_products = [
                {
                    'name': f'Apple MacBook Pro M4 Pro 14" - {query}',
                    'price': '8999,00 z≈Ç',
                    'url': f'https://allegro.pl/listing?string={quote_plus(query)}',
                    'image': 'https://via.placeholder.com/200x200?text=MacBook',
                    'seller': 'Autoryzowany sprzedawca Apple',
                    'availability': 'Dostawa w 48h',
                    'rating': '‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ (4.9/5)',
                    'description': f'–ò—Å—Ç–æ—á–Ω–∏–∫: Allegro (demo), –ü–æ–∏—Å–∫: {query}',
                    'relevance_score': 98.0
                }
            ]
        else:
            mock_products = [
                {
                    'name': f'Produkt zwiƒÖzany z "{query}" - Najlepszy wyb√≥r',
                    'price': '299,99 z≈Ç',
                    'url': f'https://allegro.pl/listing?string={quote_plus(query)}',
                    'image': 'https://via.placeholder.com/200x200?text=Product',
                    'seller': 'Sprawdzony sprzedawca',
                    'availability': 'Dostawa gratis',
                    'rating': '‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ (4.2/5)',
                    'description': f'–ò—Å—Ç–æ—á–Ω–∏–∫: Allegro (demo), –ü–æ–∏—Å–∫: {query}',
                    'relevance_score': 75.0
                }
            ]

        logger.info(f"üé≠ –°–æ–∑–¥–∞–Ω–æ {len(mock_products)} –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
        return mock_products

    def _parse_api_response(self, data: Dict, query: str) -> List[Dict[str, Any]]:
        """–ü–∞—Ä—Å–∏—Ç –æ—Ç–≤–µ—Ç –æ—Ç API"""
        try:
            products = []
            items = data.get('items', [])

            for item in items[:10]:  # –ú–∞–∫—Å–∏–º—É–º 10 —Ç–æ–≤–∞—Ä–æ–≤
                try:
                    name = item.get('name') or item.get('title') or item.get('offer', {}).get('name', '')
                    price = item.get('price') or item.get('offer', {}).get('price', {}).get('amount', '')
                    url = item.get('url') or item.get('offer', {}).get('url', '')

                    if name and self._calculate_relevance_score(name, query) > 20:
                        products.append({
                            'name': name,
                            'price': f"{price} z≈Ç" if price else "–¶–µ–Ω–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞",
                            'url': url if url.startswith('http') else f"https://allegro.pl{url}",
                            'image': item.get('image', ''),
                            'seller': item.get('seller', {}).get('name', '–ü—Ä–æ–¥–∞–≤–µ—Ü –Ω–µ —É–∫–∞–∑–∞–Ω'),
                            'availability': 'Dostƒôpny',
                            'rating': '–†–µ–π—Ç–∏–Ω–≥ –Ω–µ —É–∫–∞–∑–∞–Ω',
                            'description': f'–ò—Å—Ç–æ—á–Ω–∏–∫: Allegro API, –ü–æ–∏—Å–∫: {query}',
                            'relevance_score': self._calculate_relevance_score(name, query)
                        })
                except:
                    continue

            return products

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ API –æ—Ç–≤–µ—Ç–∞: {e}")
            return []

    def _parse_simple_html(self, html: str, query: str) -> List[Dict[str, Any]]:
        """–ü–∞—Ä—Å–∏—Ç HTML –ø—Ä–æ—Å—Ç—ã–º —Å–ø–æ—Å–æ–±–æ–º –¥–ª—è fallback"""
        try:
            from bs4 import BeautifulSoup
            soup = BeautifulSoup(html, 'html.parser')

            products = []

            # –ò—â–µ–º —Ç–æ–≤–∞—Ä—ã –≤ HTML
            product_elements = soup.find_all(['article', 'div'], attrs={'data-role': 'offer'}) or \
                             soup.find_all('a', href=lambda x: x and '/oferta/' in x)[:20]

            for element in product_elements[:15]:  # –ú–∞–∫—Å–∏–º—É–º 15 —Ç–æ–≤–∞—Ä–æ–≤
                try:
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ
                    title_elem = element.find('a', href=lambda x: x and '/oferta/' in x)
                    if not title_elem:
                        continue

                    title = title_elem.get('title') or title_elem.get_text(strip=True)
                    url = title_elem.get('href')

                    if not title or not url:
                        continue

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å
                    relevance = self._calculate_relevance_score(title, query)
                    if relevance < 20.0:
                        continue

                    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ü–µ–Ω—É
                    price = "–¶–µ–Ω–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞"
                    price_elem = element.find(string=lambda text: text and 'z≈Ç' in text)
                    if price_elem:
                        price = price_elem.strip()

                    # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º URL
                    if url.startswith('/'):
                        url = f"https://allegro.pl{url}"

                    products.append({
                        'name': title,
                        'price': price,
                        'url': url,
                        'image': '',
                        'seller': '–ü—Ä–æ–¥–∞–≤–µ—Ü –Ω–µ —É–∫–∞–∑–∞–Ω',
                        'availability': '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–æ—Å—Ç–∞–≤–∫–µ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞',
                        'rating': '–†–µ–π—Ç–∏–Ω–≥ –Ω–µ —É–∫–∞–∑–∞–Ω',
                        'description': f"–ò—Å—Ç–æ—á–Ω–∏–∫: Allegro (fallback), –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {relevance:.1f}",
                        'relevance_score': relevance
                    })

                except Exception as e:
                    logger.debug(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —ç–ª–µ–º–µ–Ω—Ç–∞: {e}")
                    continue

            logger.info(f"üîÑ Fallback –ø–æ–∏—Å–∫: –Ω–∞–π–¥–µ–Ω–æ {len(products)} —Ç–æ–≤–∞—Ä–æ–≤")
            return products

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ—Å—Ç–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞ HTML: {e}")
            return []


# –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ–º
async def search_allegro_enhanced(query: str, max_pages: int = 1, debug_mode: bool = False) -> List[Dict[str, Any]]:
    """
    –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞ –Ω–∞ Allegro —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –æ–±—Ö–æ–¥–æ–º –∑–∞—â–∏—Ç—ã
    """
    try:
        scraper = AllegroEnhancedScraper()

        # –û—Å–Ω–æ–≤–Ω–æ–π –ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ Playwright
        logger.info(f"üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ Allegro: '{query}'")
        products = await scraper.search_products(query, max_pages)

        # –ï—Å–ª–∏ –æ—Å–Ω–æ–≤–Ω–æ–π –ø–æ–∏—Å–∫ –Ω–µ –¥–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤, –ø—Ä–æ–±—É–µ–º fallback
        if not products:
            logger.info("üîÑ –û—Å–Ω–æ–≤–Ω–æ–π –ø–æ–∏—Å–∫ –Ω–µ –¥–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤, –ø—Ä–æ–±—É–µ–º fallback...")
            products = scraper._fallback_simple_search(query)

        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        if products:
            products = products[:20]  # –ú–∞–∫—Å–∏–º—É–º 20 —Ç–æ–≤–∞—Ä–æ–≤
            logger.info(f"‚úÖ Allegro –ø–æ–∏—Å–∫ –∑–∞–≤–µ—Ä—à–µ–Ω: {len(products)} —Ç–æ–≤–∞—Ä–æ–≤")
        else:
            logger.warning("‚ùå Allegro: —Ç–æ–≤–∞—Ä—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")

        return products

    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ Allegro: {e}")
        return []


# –°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
def search_allegro_enhanced_sync(query: str, max_pages: int = 1, debug_mode: bool = False) -> List[Dict[str, Any]]:
    """
    –°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –ø–æ–∏—Å–∫–∞ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å –æ—Å–Ω–æ–≤–Ω—ã–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ–º
    """
    try:
        return asyncio.run(search_allegro_enhanced(query, max_pages, debug_mode))
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞: {e}")
        return []


# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
async def test_enhanced_search():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –Ω–æ–≤—ã–π —É–ª—É—á—à–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫"""
    test_queries = [
        "macbook m4 pro",
        "iphone 15",
        "samsung galaxy s24",
        "laptop gaming"
    ]

    for query in test_queries:
        logger.info(f"\n{'='*60}")
        logger.info(f"üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å: '{query}'")
        logger.info(f"{'='*60}")

        results = await search_allegro_enhanced(query, max_pages=1, debug_mode=True)

        if results:
            logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(results)} —Ç–æ–≤–∞—Ä–æ–≤:")
            for i, product in enumerate(results[:5], 1):
                logger.info(f"{i}. {product['name'][:60]}...")
                logger.info(f"   üí∞ {product['price']}")
                logger.info(f"   üè™ {product['seller']}")
                logger.info(f"   üìä –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {product['relevance_score']:.1f}")
                logger.info(f"   üîó {product['url'][:80]}...")
                logger.info("")
        else:
            logger.warning(f"‚ùå –¢–æ–≤–∞—Ä—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: '{query}'")

        # –ü–∞—É–∑–∞ –º–µ–∂–¥—É —Ç–µ—Å—Ç–∞–º–∏
        await asyncio.sleep(3)


if __name__ == "__main__":

    asyncio.run(test_enhanced_search())
