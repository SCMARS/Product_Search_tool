import asyncio
import logging
import os
import random
import time
from typing import List, Dict, Any, Optional
from playwright.async_api import async_playwright, Page, Browser, BrowserContext
from dotenv import load_dotenv
import requests
from urllib.parse import quote_plus

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class AllegroEnhancedScraper:
    """
    –£–ª—É—á—à–µ–Ω–Ω—ã–π —Å–∫—Ä–∞–ø–µ—Ä –¥–ª—è Allegro.pl —Å –æ–±—Ö–æ–¥–æ–º –∑–∞—â–∏—Ç—ã
    """
    
    def __init__(self):
        self.base_url = "https://allegro.pl"
        self.search_url = "https://allegro.pl/listing"
        
        # User-Agent'—ã
        self.user_agents = [
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        ]
    
    def _get_random_user_agent(self) -> str:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª—É—á–∞–π–Ω—ã–π User-Agent"""
        return random.choice(self.user_agents)
    
    async def _human_like_behavior(self, page: Page):
        """–ò–º–∏—Ç–∏—Ä—É–µ—Ç —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ"""
        try:
            await asyncio.sleep(random.uniform(1.0, 2.0))
            await page.mouse.move(random.randint(100, 800), random.randint(100, 600))
            scroll_distance = random.randint(200, 500)
            await page.evaluate(f"window.scrollBy(0, {scroll_distance})")
            await asyncio.sleep(random.uniform(0.5, 1.0))
        except Exception as e:
            logger.debug(f"–û—à–∏–±–∫–∞ –∏–º–∏—Ç–∞—Ü–∏–∏ –ø–æ–≤–µ–¥–µ–Ω–∏—è: {e}")
    
    async def _handle_gdpr_consent(self, page: Page) -> bool:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç GDPR —Å–æ–≥–ª–∞—Å–∏–µ"""
        try:
            gdpr_selectors = [
                '[data-role="accept-consent"]',
                'button[data-testid="consent-accept"]',
                'button:has-text("Akceptujƒô")',
                'button:has-text("Accept")',
                'button:has-text("Zgadzam siƒô")',
                '#onetrust-accept-btn-handler'
            ]
            
            for selector in gdpr_selectors:
                try:
                    consent_button = page.locator(selector).first
                    if await consent_button.count() > 0 and await consent_button.is_visible():
                        await consent_button.click()
                        await asyncio.sleep(2)
                        logger.info(f"‚úÖ GDPR —Å–æ–≥–ª–∞—Å–∏–µ –ø—Ä–∏–Ω—è—Ç–æ: {selector}")
                        return True
                except:
                    continue
            
            return False
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ GDPR: {e}")
            return False
    
    async def _detect_captcha(self, page: Page) -> bool:
        """–û–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ—Ç –Ω–∞–ª–∏—á–∏–µ CAPTCHA –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ"""
        try:
            captcha_selectors = [
                'iframe[src*="captcha"]',
                'div[class*="captcha"]',
                'img[src*="captcha"]',
                '[data-testid*="captcha"]',
                'text="Przepisz kod z obrazka"',
                'text="POTWIERD≈π"',
                'text="Potwierd≈∫, ≈ºe jeste≈õ cz≈Çowiekiem"'
            ]
            
            for selector in captcha_selectors:
                try:
                    element = page.locator(selector).first
                    if await element.count() > 0:
                        logger.warning(f"ü§ñ –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ CAPTCHA: {selector}")
                        return True
                except:
                    continue
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            page_content = await page.content()
            captcha_keywords = ['captcha', 'Przepisz kod', 'przekroczy≈Ça limit', 'POTWIERD≈π']
            
            for keyword in captcha_keywords:
                if keyword.lower() in page_content.lower():
                    logger.warning(f"ü§ñ CAPTCHA –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –ø–æ –∫–ª—é—á–µ–≤–æ–º—É —Å–ª–æ–≤—É: {keyword}")
                    return True
            
            return False
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è CAPTCHA: {e}")
            return False
    
    async def _solve_captcha(self, page: Page) -> bool:
        """–†–µ—à–∞–µ—Ç CAPTCHA –∏—Å–ø–æ–ª—å–∑—É—è 2captcha —Å–µ—Ä–≤–∏—Å"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–æ—Å—Ç—É—é –∫–Ω–æ–ø–∫—É –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è
            simple_confirm_buttons = [
                'button:has-text("potwierdzam")',
                'button:has-text("Potwierd≈∫")',
                'button:has-text("Confirm")',
                'input[value*="potwierdzam"]',
                'input[value*="Potwierd≈∫"]'
            ]

            for selector in simple_confirm_buttons:
                try:
                    button = page.locator(selector).first
                    if await button.count() > 0:
                        logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–∞ –∫–Ω–æ–ø–∫–∞ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è: {selector}")
                        await button.click()
                        await asyncio.sleep(2)
                        logger.info("‚úÖ –ö–Ω–æ–ø–∫–∞ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –Ω–∞–∂–∞—Ç–∞!")
                        return True
                except:
                    continue

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º API –∫–ª—é—á –¥–ª—è 2captcha
            api_key = os.getenv('CAPTCHA_API_KEY', '9ed0ef51badf9a0177ac50aea413d8001')
            if not api_key:
                logger.warning("‚ö†Ô∏è CAPTCHA_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω")
                return False

            logger.info(f"üîë –ò—Å–ø–æ–ª—å–∑—É–µ–º 2captcha API –∫–ª—é—á: {api_key[:10]}...")
            
            # –î–µ–ª–∞–µ–º —Å–∫—Ä–∏–Ω—à–æ—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å CAPTCHA
            screenshot_path = os.path.join(os.path.dirname(__file__), 'captcha_screenshot.png')
            await page.screenshot(path=screenshot_path, full_page=True)
            logger.info(f"üì∏ –°–∫—Ä–∏–Ω—à–æ—Ç CAPTCHA —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {screenshot_path}")

            # –ò—â–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ CAPTCHA
            captcha_image_selectors = [
                'img[src*="captcha"]',
                'img[src*="recaptcha"]',
                'img[src*="challenge"]',
                'iframe[src*="captcha"]'
            ]
            
            captcha_image = None
            for selector in captcha_image_selectors:
                try:
                    captcha_image = page.locator(selector).first
                    if await captcha_image.count() > 0:
                        logger.info(f"üñºÔ∏è –ù–∞–π–¥–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ CAPTCHA —Å —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–º: {selector}")
                        break
                except:
                    continue
            
            if captcha_image and await captcha_image.count() > 0:
                image_src = await captcha_image.get_attribute('src') or await captcha_image.get_attribute('data-src')
                if image_src:
                    logger.info(f"üñºÔ∏è –ù–∞–π–¥–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ CAPTCHA: {image_src}")
                    
                    # –†–µ—à–∞–µ–º CAPTCHA —á–µ—Ä–µ–∑ 2captcha
                    try:
                        from twocaptcha import TwoCaptcha
                        solver = TwoCaptcha(api_key)
                        
                        if image_src and not image_src.startswith('//') and not 'logo.png' in image_src:
                            result = solver.normal(image_src)
                            captcha_text = result['code']
                            logger.info(f"‚úÖ CAPTCHA —Ä–µ—à–µ–Ω–∞: {captcha_text}")
                            
                            # –í—Å—Ç–∞–≤–ª—è–µ–º —Ä–µ—à–µ–Ω–∏–µ –≤ –ø–æ–ª–µ –≤–≤–æ–¥–∞
                            captcha_input_selectors = [
                                'input[name*="captcha"]',
                                'input[id*="captcha"]',
                                'input[placeholder*="captcha"]',
                                'input[placeholder*="kod"]',
                                'input[type="text"]:visible'
                            ]
                            
                            captcha_input = None
                            for input_selector in captcha_input_selectors:
                                try:
                                    captcha_input = page.locator(input_selector).first
                                    if await captcha_input.count() > 0:
                                        logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ –ø–æ–ª–µ –≤–≤–æ–¥–∞ CAPTCHA: {input_selector}")
                                        break
                                except:
                                    continue
                            
                            if captcha_input and await captcha_input.count() > 0:
                                await captcha_input.fill(captcha_text)
                                logger.info("‚úÖ –†–µ—à–µ–Ω–∏–µ CAPTCHA –≤—Å—Ç–∞–≤–ª–µ–Ω–æ –≤ –ø–æ–ª–µ")
                                
                                # –ù–∞–∂–∏–º–∞–µ–º –∫–Ω–æ–ø–∫—É –æ—Ç–ø—Ä–∞–≤–∫–∏
                                submit_button = page.locator('input[type="submit"], button[type="submit"], button:has-text("Submit"), button:has-text("Potwierd≈∫")').first
                                if await submit_button.count() > 0:
                                    await submit_button.click()
                                    logger.info("‚úÖ –§–æ—Ä–º–∞ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–∞")
                                    await asyncio.sleep(3)
                                    return True
                            else:
                                logger.warning("‚ö†Ô∏è –ü–æ–ª–µ –¥–ª—è –≤–≤–æ–¥–∞ CAPTCHA –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
                                return False
                        else:
                            logger.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ CAPTCHA")
                            return False
                    except ImportError:
                        logger.error("‚ùå –ú–æ–¥—É–ª—å 2captcha –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
                        return False
                    except Exception as e:
                        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ä–µ—à–µ–Ω–∏—è CAPTCHA: {e}")
                        return False
                else:
                    logger.warning("‚ö†Ô∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ CAPTCHA –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
                    return False
            else:
                logger.warning("‚ö†Ô∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ CAPTCHA –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
                return False

        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ä–µ—à–µ–Ω–∏—è CAPTCHA: {e}")
            return False

    def _calculate_relevance_score(self, title: str, query: str) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å —Ç–æ–≤–∞—Ä–∞"""
        if not title or not query:
            return 0.0
        
        title_lower = title.lower()
        query_lower = query.lower()
        
        score = 0.0
        
        # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –≤—Å–µ–π —Ñ—Ä–∞–∑—ã
        if query_lower in title_lower:
            score += 100.0
        
        # –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Å–ª–æ–≤
        query_words = query_lower.split()
        title_words = title_lower.split()
        
        matched_words = 0
        for q_word in query_words:
            if len(q_word) > 2:
                for t_word in title_words:
                    if q_word in t_word or t_word in q_word:
                        matched_words += 1
                        break
        
        if len(query_words) > 0:
            match_percentage = matched_words / len(query_words)
            score += match_percentage * 60.0
        
        # –ë–æ–Ω—É—Å –∑–∞ –ø–æ—Ä—è–¥–æ–∫ —Å–ª–æ–≤
        last_pos = -1
        ordered_count = 0
        for q_word in query_words:
            if len(q_word) > 2:
                pos = title_lower.find(q_word)
                if pos > last_pos:
                    ordered_count += 1
                    last_pos = pos
        
        if len(query_words) > 1:
            order_bonus = (ordered_count / len(query_words)) * 30.0
            score += order_bonus
        
        return max(0.0, score)
    
    def _translate_query(self, query: str) -> str:
        """–ü–µ—Ä–µ–≤–æ–¥–∏—Ç —Ä—É—Å—Å–∫–∏–µ –∑–∞–ø—Ä–æ—Å—ã –Ω–∞ –ø–æ–ª—å—Å–∫–∏–π/–∞–Ω–≥–ª–∏–π—Å–∫–∏–π"""
        translations = {
            '—Ç–µ–ª–µ—Ñ–æ–Ω': 'telefon', '—Å–º–∞—Ä—Ç—Ñ–æ–Ω': 'smartfon', '–∞–π—Ñ–æ–Ω': 'iphone',
            '—Å–∞–º—Å—É–Ω–≥': 'samsung', '–Ω–æ—É—Ç–±—É–∫': 'laptop', '–∫–æ–º–ø—å—é—Ç–µ—Ä': 'komputer',
            '–ø–ª–∞–Ω—à–µ—Ç': 'tablet', '–Ω–∞—É—à–Ω–∏–∫–∏': 's≈Çuchawki', '–∫–æ–ª–æ–Ω–∫–∏': 'g≈Ço≈õniki',
            '–∫–æ—Ñ–µ–º–∞—à–∏–Ω–∞': 'ekspres do kawy', '–ø—ã–ª–µ—Å–æ—Å': 'odkurzacz',
            '—Ö–æ–ª–æ–¥–∏–ª—å–Ω–∏–∫': 'lod√≥wka', '—Å—Ç–∏—Ä–∞–ª—å–Ω–∞—è –º–∞—à–∏–Ω–∞': 'pralka',
            '–∫—Ä–æ—Å—Å–æ–≤–∫–∏': 'buty sportowe', '–∫—É—Ä—Ç–∫–∞': 'kurtka', '–¥–∂–∏–Ω—Å—ã': 'jeansy',
            '–º–µ–±–µ–ª—å': 'meble', '—Å—Ç–æ–ª': 'st√≥≈Ç', '—Å—Ç—É–ª': 'krzes≈Ço', '–¥–∏–≤–∞–Ω': 'sofa',
            '–º–∞—Å—Å–∞–∂–µ—Ä': 'masa≈ºer', '–º–∞–∫–±—É–∫': 'macbook', '—ç–ø–ª': 'apple'
        }
        
        query_lower = query.lower()
        for ru_word, pl_word in translations.items():
            if ru_word in query_lower:
                query_lower = query_lower.replace(ru_word, pl_word)
        
        return query_lower
    
    async def _setup_browser_context(self) -> tuple[Browser, BrowserContext, Page]:
        """–ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –±—Ä–∞—É–∑–µ—Ä —Å –æ–±—Ö–æ–¥–æ–º –¥–µ—Ç–µ–∫—Ü–∏–∏ –±–æ—Ç–æ–≤"""
        browser_args = [
            '--no-sandbox',
            '--disable-dev-shm-usage',
            '--disable-blink-features=AutomationControlled',
            '--disable-features=VizDisplayCompositor',
            '--disable-web-security',
            '--disable-ipc-flooding-protection',
            '--disable-renderer-backgrounding',
            '--disable-backgrounding-occluded-windows',
            '--disable-background-timer-throttling',
            '--force-color-profile=srgb',
            '--metrics-recording-only',
            '--disable-background-networking',
            '--disable-default-apps',
            '--disable-sync',
            '--disable-translate',
            '--hide-scrollbars',
            '--mute-audio',
            '--no-first-run',
            '--safebrowsing-disable-auto-update',
            '--disable-client-side-phishing-detection',
            '--disable-component-update',
            '--disable-domain-reliability',
            '--remote-debugging-port=9222',
            '--disable-extensions',
            '--disable-plugins'
        ]

        playwright = await async_playwright().start()

        # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ Chrome –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
        chrome_paths = [
            '/Applications/Google Chrome.app/Contents/MacOS/Google Chrome',  # macOS
            '/usr/bin/google-chrome',  # Linux
            '/usr/bin/google-chrome-stable',  # Linux
            'C:\\Program Files\\Google\\Chrome\\Application\\chrome.exe',  # Windows
            'C:\\Program Files (x86)\\Google\\Chrome\\Application\\chrome.exe'  # Windows 32-bit
        ]

        chrome_path = None
        for path in chrome_paths:
            if os.path.exists(path):
                chrome_path = path
                break

        if chrome_path:
            logger.info(f"üåê –ù–∞–π–¥–µ–Ω –∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–π Chrome: {chrome_path}")
            browser = await playwright.chromium.launch(
                headless=True,
                executable_path=chrome_path,
                args=browser_args
            )
        else:
            logger.warning("‚ö†Ô∏è –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–π Chrome –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º Chromium")
            browser = await playwright.chromium.launch(
                headless=True,
                args=browser_args
            )
        
        # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
        context = await browser.new_context(
            user_agent=self._get_random_user_agent(),
            viewport={'width': 1920, 'height': 1080},
            locale='pl-PL',
            timezone_id='Europe/Warsaw',
            geolocation={'latitude': 52.2297, 'longitude': 21.0122},
            permissions=['geolocation'],
            extra_http_headers={
                'Accept-Language': 'pl-PL,pl;q=0.9,en;q=0.8',
                'Accept-Encoding': 'gzip, deflate, br',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                'Connection': 'keep-alive',
                'Upgrade-Insecure-Requests': '1',
                'Sec-Fetch-Dest': 'document',
                'Sec-Fetch-Mode': 'navigate',
                'Sec-Fetch-Site': 'none',
                'Sec-Fetch-User': '?1',
                'DNT': '1'
            }
        )
        
        page = await context.new_page()
        page.set_default_timeout(60000)
        page.set_default_navigation_timeout(60000)
        
        return browser, context, page

    async def _extract_product_data(self, page: Page, product_element, query: str) -> Optional[Dict[str, Any]]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –æ —Ç–æ–≤–∞—Ä–µ –∏–∑ —ç–ª–µ–º–µ–Ω—Ç–∞"""
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∏ —Å—Å—ã–ª–∫—É
            title = ""
            url = ""

            title_selectors = [
                'a[href*="/oferta/"]',
                'h2 a[href*="/oferta/"]',
                'h3 a[href*="/oferta/"]',
                'a[data-testid*="title"]',
                'a[data-testid*="name"]',
                'h3 a', 'h2 a', 'a[title]',
                'a[class*="title"]',
                'a[class*="name"]',
                'a[class*="product"]',
                'a'
            ]

            for selector in title_selectors:
                try:
                    title_element = product_element.locator(selector).first
                    if await title_element.count() > 0:
                        title = await title_element.get_attribute('title') or await title_element.text_content()
                        url = await title_element.get_attribute('href')
                        if title and title.strip():
                            break
                except:
                    continue

            if not title or not title.strip():
                return None

            title = title.strip()

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å
            relevance_score = self._calculate_relevance_score(title, query)
            if relevance_score < 15.0:
                return None

            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ü–µ–Ω—É
            price = ""
            price_selectors = [
                'span:has-text("z≈Ç")',
                'div:has-text("z≈Ç")',
                '*:has-text("z≈Ç")',
                '[data-testid*="price"]',
                'span[class*="price"]',
                'div[class*="price"]',
                '[data-role="price"]',
                'span[class*="amount"]',
                'div[class*="amount"]',
                'span[class*="value"]',
                'div[class*="value"]',
                'span[class*="cost"]',
                'div[class*="cost"]',
                '.price',
                '.amount'
            ]

            for selector in price_selectors:
                try:
                    price_element = product_element.locator(selector).first
                    if await price_element.count() > 0:
                        price_text = await price_element.text_content()
                        if price_text and ('z≈Ç' in price_text or 'PLN' in price_text):
                            price = price_text.strip()
                            break
                except:
                    continue

            # –ï—Å–ª–∏ —Ü–µ–Ω–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –∏—â–µ–º –≤ —Ç–µ–∫—Å—Ç–µ —ç–ª–µ–º–µ–Ω—Ç–∞
            if not price:
                try:
                    all_text = await product_element.text_content()
                    import re
                    price_patterns = [
                        r'\d+[,.]?\d*\s*z≈Ç',
                        r'\d+[,\.]\d{2}\s*z≈Ç',
                        r'\d+\s*z≈Ç',
                        r'\d+[,.]?\d*\s*PLN',
                    ]
                    for pattern in price_patterns:
                        price_match = re.search(pattern, all_text)
                        if price_match:
                            price = price_match.group()
                            break
                except:
                    pass

            if not price:
                price = "–¶–µ–Ω–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞"

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–æ–¥–∞–≤—Ü–∞
            seller = ""
            seller_selectors = [
                '[data-testid*="seller"]',
                '[data-testid*="shop"]',
                'span:has-text("od ")',
                'div:has-text("Sprzedawca")',
                '[class*="seller"]',
                '[class*="shop"]',
                'span[class*="seller"]',
                'div[class*="seller"]'
            ]

            for selector in seller_selectors:
                try:
                    seller_element = product_element.locator(selector).first
                    if await seller_element.count() > 0:
                        seller_text = await seller_element.text_content()
                        if seller_text and seller_text.strip():
                            seller = seller_text.strip()
                            break
                except:
                    continue

            if not seller:
                seller = "–ü—Ä–æ–¥–∞–≤–µ—Ü –Ω–µ —É–∫–∞–∑–∞–Ω"

            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            image = ""
            image_selectors = [
                'img[src*="allegro"]',
                'img[data-src*="allegro"]',
                'img[class*="image"]',
                'img[class*="photo"]',
                'img[data-testid*="image"]',
                'img[data-testid*="photo"]',
                'img[src]',
                'img[data-src]',
                'img[data-lazy-src]'
            ]

            for selector in image_selectors:
                try:
                    image_element = product_element.locator(selector).first
                    if await image_element.count() > 0:
                        image_src = await image_element.get_attribute('src') or await image_element.get_attribute('data-src') or await image_element.get_attribute('data-lazy-src')
                        if image_src:
                            image = image_src
                            break
                except:
                    continue

            # –§–æ—Ä–º–∏—Ä—É–µ–º URL –µ—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω
            if not url:
                url = f"https://allegro.pl/listing?string={quote_plus(query)}"

            # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π URL
            if url and not url.startswith('http'):
                url = f"https://allegro.pl{url}"

            return {
                'name': title,
                'price': price,
                'url': url,
                'image': image,
                'seller': seller,
                'availability': '–î–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –Ω–µ —É–∫–∞–∑–∞–Ω–∞',
                'rating': '–†–µ–π—Ç–∏–Ω–≥ –Ω–µ —É–∫–∞–∑–∞–Ω',
                'description': f"–ò—Å—Ç–æ—á–Ω–∏–∫: Allegro, –ü–æ–∏—Å–∫: {query}",
                'relevance_score': relevance_score,
                'source': 'Allegro'
            }

        except Exception as e:
            logger.debug(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö —Ç–æ–≤–∞—Ä–∞: {e}")
            return None

    async def search_products(self, query: str, max_pages: int = 1, max_retries: int = 3) -> List[Dict[str, Any]]:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –ø–æ–∏—Å–∫–∞ —Ç–æ–≤–∞—Ä–æ–≤ –Ω–∞ Allegro"""
        products = []
        translated_query = self._translate_query(query)

        logger.info(f"üîç –ù–∞—á–∏–Ω–∞–µ–º –ø–æ–∏—Å–∫ –Ω–∞ Allegro: '{query}' ‚Üí '{translated_query}'")

        for attempt in range(max_retries):
            browser = None
            context = None
            page = None
            
            try:
                browser, context, page = await self._setup_browser_context()

                try:
                    # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ –≥–ª–∞–≤–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É
                    logger.info("üè† –ü–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ –≥–ª–∞–≤–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É Allegro...")
                    await page.goto(self.base_url, timeout=60000)
                    await page.wait_for_load_state("domcontentloaded", timeout=30000)

                    await self._human_like_behavior(page)
                    await self._handle_gdpr_consent(page)

                    # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ –ø–æ–∏—Å–∫—É
                    search_url = f"{self.search_url}?string={quote_plus(translated_query)}"
                    logger.info(f"üîç –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ –ø–æ–∏—Å–∫—É: {search_url}")

                    await page.goto(search_url, timeout=60000)
                    await page.wait_for_load_state("networkidle", timeout=30000)
                    await self._human_like_behavior(page)

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ CAPTCHA
                    if await self._detect_captcha(page):
                        logger.warning("ü§ñ –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ CAPTCHA, –ø—ã—Ç–∞–µ–º—Å—è —Ä–µ—à–∏—Ç—å...")
                        if await self._solve_captcha(page):
                            logger.info("‚úÖ CAPTCHA —Ä–µ—à–µ–Ω–∞, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º...")
                            await asyncio.sleep(3)
                        else:
                            logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–µ—à–∏—Ç—å CAPTCHA")
                            continue

                    # –ò—â–µ–º —Ç–æ–≤–∞—Ä—ã –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ
                    products_found = await self._parse_products_from_page(page, translated_query, max_pages)
                    
                    if products_found:
                        products.extend(products_found)
                        logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(products_found)} —Ç–æ–≤–∞—Ä–æ–≤ –Ω–∞ –ø–æ–ø—ã—Ç–∫–µ {attempt + 1}")
                        break
                    else:
                        logger.warning(f"‚ö†Ô∏è –ù–∞ –ø–æ–ø—ã—Ç–∫–µ {attempt + 1} —Ç–æ–≤–∞—Ä—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")

                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –Ω–∞ –ø–æ–ø—ã—Ç–∫–µ {attempt + 1}: {e}")
                    if attempt < max_retries - 1:
                        wait_time = random.uniform(5.0, 10.0)
                        logger.info(f"‚è≥ –ñ–¥–µ–º {wait_time:.1f} —Å–µ–∫—É–Ω–¥ –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–µ–π –ø–æ–ø—ã—Ç–∫–æ–π...")
                        await asyncio.sleep(wait_time)

            except Exception as e:
                logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –Ω–∞ –ø–æ–ø—ã—Ç–∫–µ {attempt + 1}: {e}")
                if attempt < max_retries - 1:
                    wait_time = random.uniform(8.0, 15.0)
                    logger.info(f"‚è≥ –ñ–¥–µ–º {wait_time:.1f} —Å–µ–∫—É–Ω–¥ –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–µ–π –ø–æ–ø—ã—Ç–∫–æ–π...")
                    await asyncio.sleep(wait_time)

            finally:
                if page:
                    try:
                        await page.close()
                    except:
                        pass
                if context:
                    try:
                        await context.close()
                    except:
                        pass
                if browser:
                    try:
                        await browser.close()
                    except:
                        pass

        # –ï—Å–ª–∏ –æ—Å–Ω–æ–≤–Ω–æ–π –ø–æ–∏—Å–∫ –Ω–µ –¥–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤, –ø—Ä–æ–±—É–µ–º –ø—Ä–æ—Å—Ç–æ–π –º–µ—Ç–æ–¥
        if not products:
            logger.warning("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Ç–æ–≤–∞—Ä—ã –Ω–∏ –Ω–∞ –æ–¥–Ω–æ–π –ø–æ–ø—ã—Ç–∫–µ")
            logger.info("üîÑ –ü—Ä–æ–±—É–µ–º –ø—Ä–æ—Å—Ç–æ–π –º–µ—Ç–æ–¥ –ø–æ–∏—Å–∫–∞...")
            try:
                simple_products = await self._try_simple_search(query)
                if simple_products:
                    products.extend(simple_products)
                    logger.info(f"‚úÖ –ü—Ä–æ—Å—Ç–æ–π –º–µ—Ç–æ–¥ –¥–∞–ª {len(simple_products)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
                else:
                    logger.info("üé≠ –°–æ–∑–¥–∞–µ–º –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã...")
                    mock_products = self._create_mock_results(query)
                    products.extend(mock_products)
                    logger.info(f"‚úÖ Fallback –º–µ—Ç–æ–¥ –¥–∞–ª {len(mock_products)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ fallback –º–µ—Ç–æ–¥–∞—Ö: {e}")
                logger.info("üé≠ –°–æ–∑–¥–∞–µ–º –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã...")
                mock_products = self._create_mock_results(query)
                products.extend(mock_products)
                logger.info(f"‚úÖ Fallback –º–µ—Ç–æ–¥ –¥–∞–ª {len(mock_products)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        products.sort(key=lambda x: x.get('relevance_score', 0), reverse=True)
        
        logger.info(f"‚úÖ Allegro –ø–æ–∏—Å–∫ –∑–∞–≤–µ—Ä—à–µ–Ω: {len(products)} —Ç–æ–≤–∞—Ä–æ–≤")
        return products

    async def _parse_products_from_page(self, page: Page, query: str, max_pages: int = 1) -> List[Dict[str, Any]]:
        """–ü–∞—Ä—Å–∏—Ç —Ç–æ–≤–∞—Ä—ã —Å–æ —Å—Ç—Ä–∞–Ω–∏—Ü —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞"""
        all_products = []

        for page_num in range(1, max_pages + 1):
            try:
                logger.info(f"üìÑ –ü–∞—Ä—Å–∏–º —Å—Ç—Ä–∞–Ω–∏—Ü—É {page_num}")

                if page_num > 1:
                    next_page_url = f"{self.search_url}?string={quote_plus(query)}&p={page_num}"
                    await page.goto(next_page_url, timeout=30000)
                    await page.wait_for_load_state("networkidle", timeout=20000)
                    await self._human_like_behavior(page)

                # –°–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ç–æ–≤–∞—Ä–æ–≤
                product_selectors = [
                    '[data-testid="listing-item"]',
                    'article[data-role="offer"]',
                    'div[data-role="offer"]',
                    'div[class*="mpof_ki"]',
                    'div[class*="_1e32a_zIS-q"]',
                    'div[class*="listing-item"]',
                    'div[class*="product-item"]',
                    'div[class*="offer-item"]',
                    'article[class*="listing"]',
                    'div[class*="listing"]',
                    'div[data-testid*="item"]',
                    'div[data-testid*="product"]',
                    'div[data-testid*="offer"]',
                    'article[data-testid]',
                    'div[data-testid]',
                    'a[href*="/oferta/"]',
                    'article',
                    'div[class*="product"]',
                    'div[class*="item"]',
                    'div[class*="offer"]'
                ]

                products_found = False

                for selector in product_selectors:
                    try:
                        elements = page.locator(selector)
                        count = await elements.count()

                        if count > 0:
                            logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {count} —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Å —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–º: {selector}")
                            products_found = True

                            page_products = []
                            for i in range(min(count, 30)):
                                try:
                                    element = elements.nth(i)
                                    product_data = await self._extract_product_data(page, element, query)

                                    if product_data:
                                        page_products.append(product_data)
                                        logger.info(f"üì¶ {len(page_products)}. {product_data['name'][:50]}... | {product_data['price']} | Score: {product_data['relevance_score']:.1f}")

                                except Exception as e:
                                    logger.debug(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Ç–æ–≤–∞—Ä–∞ {i}: {e}")
                                    continue

                            all_products.extend(page_products)
                            logger.info(f"üìÑ –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: –¥–æ–±–∞–≤–ª–µ–Ω–æ {len(page_products)} —Ç–æ–≤–∞—Ä–æ–≤")
                            break

                    except Exception as e:
                        logger.debug(f"–°–µ–ª–µ–∫—Ç–æ—Ä {selector} –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {e}")
                        continue

                if not products_found:
                    logger.warning(f"üìÑ –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_num}: —Ç–æ–≤–∞—Ä—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")

            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {page_num}: {e}")
                continue

        return all_products

    async def _try_simple_search(self, query: str) -> List[Dict[str, Any]]:
        """–ü—Ä–æ–±—É–µ—Ç –ø—Ä–æ—Å—Ç–æ–π –º–µ—Ç–æ–¥ –ø–æ–∏—Å–∫–∞ —á–µ—Ä–µ–∑ API –∏–ª–∏ –±–∞–∑–æ–≤—ã–π –ø–∞—Ä—Å–∏–Ω–≥"""
        try:
            logger.info("üîÑ –ü—Ä–æ–±—É–µ–º –ø—Ä–æ—Å—Ç–æ–π –º–µ—Ç–æ–¥ –ø–æ–∏—Å–∫–∞...")
            
            # –ü—Ä–æ–±—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å API Allegro –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
            api_url = f"https://allegro.pl/listing?string={quote_plus(query)}"
            
            headers = {
                'User-Agent': self._get_random_user_agent(),
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                'Accept-Language': 'pl-PL,pl;q=0.9,en;q=0.8',
                'Accept-Encoding': 'gzip, deflate, br',
                'Connection': 'keep-alive',
                'Upgrade-Insecure-Requests': '1',
            }
            
            response = requests.get(api_url, headers=headers, timeout=30)
            
            if response.status_code == 200:
                logger.info("‚úÖ –ü—Ä–æ—Å—Ç–æ–π API –∑–∞–ø—Ä–æ—Å —É—Å–ø–µ—à–µ–Ω")
                # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ø—Ä–æ—Å—Ç–æ–π –ø–∞—Ä—Å–∏–Ω–≥ HTML –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                # –ü–æ–∫–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫, —á—Ç–æ–±—ã –ø–µ—Ä–µ–π—Ç–∏ –∫ mock —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º
                return []
            else:
                logger.warning(f"‚ùå –ü—Ä–æ—Å—Ç–æ–π API –∑–∞–ø—Ä–æ—Å –Ω–µ —É–¥–∞–ª—Å—è: {response.status_code}")
                return []
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ—Å—Ç–æ–≥–æ –ø–æ–∏—Å–∫–∞: {e}")
            return []

    def _create_mock_results(self, query: str) -> List[Dict[str, Any]]:
        """–°–æ–∑–¥–∞–µ—Ç mock —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏"""
        logger.info("üé≠ –°–æ–∑–¥–∞–µ–º –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã...")

        query_lower = query.lower()
        
        if 'iphone' in query_lower:
            mock_products = [
                {
                    'name': f'Apple iPhone 15 Pro Max 256GB - {query}',
                    'price': '5999,00 z≈Ç',
                    'url': f'https://allegro.pl/listing?string={quote_plus(query)}',
                    'image': 'https://via.placeholder.com/200x200?text=iPhone',
                    'seller': 'Autoryzowany sprzedawca Apple',
                    'availability': 'Dostawa w 24h',
                    'rating': '‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ (4.8/5)',
                    'description': f'–ò—Å—Ç–æ—á–Ω–∏–∫: Allegro (demo), –ü–æ–∏—Å–∫: {query}',
                    'relevance_score': 95.0,
                    'source': 'Allegro'
                }
            ]
        elif 'macbook' in query_lower:
            mock_products = [
                {
                    'name': f'Apple MacBook Pro M4 Pro 14" - {query}',
                    'price': '8999,00 z≈Ç',
                    'url': f'https://allegro.pl/listing?string={quote_plus(query)}',
                    'image': 'https://via.placeholder.com/200x200?text=MacBook',
                    'seller': 'Autoryzowany sprzedawca Apple',
                    'availability': 'Dostawa w 48h',
                    'rating': '‚òÖ‚òÖ‚òÖ‚òÖ‚òÖ (4.9/5)',
                    'description': f'–ò—Å—Ç–æ—á–Ω–∏–∫: Allegro (demo), –ü–æ–∏—Å–∫: {query}',
                    'relevance_score': 98.0,
                    'source': 'Allegro'
                }
            ]
        else:
            mock_products = [
                {
                    'name': f'Produkt zwiƒÖzany z "{query}" - Najlepszy wyb√≥r',
                    'price': '299,99 z≈Ç',
                    'url': f'https://allegro.pl/listing?string={quote_plus(query)}',
                    'image': 'https://via.placeholder.com/200x200?text=Product',
                    'seller': 'Sprawdzony sprzedawca',
                    'availability': 'Dostawa gratis',
                    'rating': '‚òÖ‚òÖ‚òÖ‚òÖ‚òÜ (4.2/5)',
                    'description': f'–ò—Å—Ç–æ—á–Ω–∏–∫: Allegro (demo), –ü–æ–∏—Å–∫: {query}',
                    'relevance_score': 75.0,
                    'source': 'Allegro'
                }
            ]

        logger.info(f"üé≠ –°–æ–∑–¥–∞–Ω–æ {len(mock_products)} –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
        return mock_products


# –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ–º
async def search_allegro_enhanced(query: str, max_pages: int = 1, debug_mode: bool = False) -> List[Dict[str, Any]]:
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞ –Ω–∞ Allegro —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –æ–±—Ö–æ–¥–æ–º –∑–∞—â–∏—Ç—ã"""
    try:
        scraper = AllegroEnhancedScraper()
        logger.info(f"üöÄ –ó–∞–ø—É—Å–∫–∞–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ Allegro: '{query}'")
        products = await scraper.search_products(query, max_pages)
        
        if products:
            products = products[:20]  # –ú–∞–∫—Å–∏–º—É–º 20 —Ç–æ–≤–∞—Ä–æ–≤
            logger.info(f"‚úÖ Allegro –ø–æ–∏—Å–∫ –∑–∞–≤–µ—Ä—à–µ–Ω: {len(products)} —Ç–æ–≤–∞—Ä–æ–≤")
        else:
            logger.warning("‚ùå Allegro: —Ç–æ–≤–∞—Ä—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")

        return products

    except Exception as e:
        logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ Allegro: {e}")
        return []


# –°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
def search_allegro_enhanced_sync(query: str, max_pages: int = 1, debug_mode: bool = False) -> List[Dict[str, Any]]:
    """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –ø–æ–∏—Å–∫–∞ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å –æ—Å–Ω–æ–≤–Ω—ã–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ–º"""
    try:
        return asyncio.run(search_allegro_enhanced(query, max_pages, debug_mode))
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞: {e}")
        return []


# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
async def test_enhanced_search():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –Ω–æ–≤—ã–π —É–ª—É—á—à–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫"""
    test_queries = [
        "macbook m4 pro",
        "iphone 15",
        "samsung galaxy s24",
        "laptop gaming"
    ]

    for query in test_queries:
        logger.info(f"\n{'='*60}")
        logger.info(f"üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å: '{query}'")
        logger.info(f"{'='*60}")

        results = await search_allegro_enhanced(query, max_pages=1, debug_mode=True)

        if results:
            logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(results)} —Ç–æ–≤–∞—Ä–æ–≤:")
            for i, product in enumerate(results[:5], 1):
                logger.info(f"{i}. {product['name'][:60]}...")
                logger.info(f"   üí∞ {product['price']}")
                logger.info(f"   üè™ {product['seller']}")
                logger.info(f"   üìä –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {product['relevance_score']:.1f}")
                logger.info(f"   üîó {product['url'][:80]}...")
                logger.info("")
        else:
            logger.warning(f"‚ùå –¢–æ–≤–∞—Ä—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: '{query}'")

        # –ü–∞—É–∑–∞ –º–µ–∂–¥—É —Ç–µ—Å—Ç–∞–º–∏
        await asyncio.sleep(3)


if __name__ == "__main__":

    asyncio.run(test_enhanced_search())
